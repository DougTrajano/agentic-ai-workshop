{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Dataset Generation - AI Workflow\n",
    "\n",
    "This notebook demonstrates how to generate a synthetic HR dataset for a company using AI Workflow.\n",
    "\n",
    "The dataset generation workflow follows these main phases:\n",
    "\n",
    "1. **Company Specification**: Convert user input into a structured company specification using LLM.\n",
    "2. **Demographic Ratios**: Generate demographic ratios based on company characteristics using LLM.\n",
    "3. **Database Setup**: Create the database structure with HR schema.\n",
    "4. **Business Unit Processing**: For each business unit:\n",
    "   - Add business unit and director job to database.\n",
    "   - Generate director employee (including education, compensation, and storage).\n",
    "   - Process all departments within the business unit.\n",
    "5. **Department Processing**: For each department:\n",
    "   - Add department and all job roles to database.\n",
    "   - Generate department employees in parallel batches (manager + staff).\n",
    "   - Each employee generation includes education determination, compensation calculation, and database storage.\n",
    "\n",
    "## Workflow Diagram\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "    A[User Input: Company Description] --> B[TASK: get_company_spec]\n",
    "    B --> C[Company Specification]\n",
    "    C --> D[TASK: get_demographic_ratios]\n",
    "    D --> E[Demographic Ratios]\n",
    "    \n",
    "    E --> F[TASK: create_database]\n",
    "    F --> G[Database with HR Schema Created]\n",
    "    \n",
    "    C --> H{For each Business Unit}\n",
    "    H --> I[TASK: add_business_unit_to_db]\n",
    "    I --> I1[Add Director Job to DB]\n",
    "    I1 --> I2[Add Business Unit to DB]\n",
    "    \n",
    "    I2 --> J[TASK: generate_employee - Director]\n",
    "    E --> J\n",
    "    J --> J1[Create Employee Object]\n",
    "    J1 --> J2[TASK: get_education_fields]\n",
    "    J2 --> J3[TASK: get_employee_compensation]\n",
    "    J3 --> J4[TASK: add_employee_to_db]\n",
    "    \n",
    "    J4 --> K{For each Department in BU}\n",
    "    K --> L[TASK: add_department_to_db]\n",
    "    L --> L1[Add Manager Job to DB]\n",
    "    L1 --> L2[Add All Department Jobs to DB]\n",
    "    L2 --> L3[Add Department to DB]\n",
    "    \n",
    "    L3 --> M[TASK: generate_department]\n",
    "    E --> M\n",
    "    \n",
    "    M --> N[TASK: generate_employee - Manager]\n",
    "    N --> N1[Manager: Education + Compensation + DB Storage]\n",
    "    \n",
    "    M --> O[Parallel Processing: Staff Generation]\n",
    "    O --> P{For each Job Role}\n",
    "    P --> Q[Batch Processing<br/>5 employees at a time]\n",
    "    Q --> R[TASK: generate_employee Ã— Headcount]\n",
    "    R --> R1[Staff: Education + Compensation + DB Storage]\n",
    "    \n",
    "    R1 --> S{More Job Roles?}\n",
    "    S -->|Yes| P\n",
    "    S -->|No| T{More Departments?}\n",
    "    T -->|Yes| K\n",
    "    T -->|No| U{More Business Units?}\n",
    "    U -->|Yes| H\n",
    "    U -->|No| V[Dataset Generation Completed]\n",
    "    \n",
    "    style A fill:#e1f5fe\n",
    "    style C fill:#f3e5f5\n",
    "    style E fill:#f3e5f5\n",
    "    style G fill:#e8f5e8\n",
    "    style V fill:#fff3e0\n",
    "    style B fill:#fff9c4\n",
    "    style D fill:#fff9c4\n",
    "    style F fill:#fff9c4\n",
    "    style I fill:#fff9c4\n",
    "    style J fill:#fff9c4\n",
    "    style L fill:#fff9c4\n",
    "    style M fill:#fff9c4\n",
    "    style N fill:#fff9c4\n",
    "    style R fill:#fff9c4\n",
    "    style J2 fill:#fce4ec\n",
    "    style J3 fill:#fce4ec\n",
    "    style J4 fill:#e8f5e8\n",
    "    style O fill:#f1f8e9\n",
    "    style Q fill:#f1f8e9\n",
    "```\n",
    "\n",
    "### Legend\n",
    "\n",
    "- **ðŸŸ¡ TASK**: LangGraph tasks (decorated functions)\n",
    "- **ðŸ”µ Input/Output**: User input and final result\n",
    "- **ðŸŸ£ Data Models**: Structured data objects\n",
    "- **ðŸŸ¢ Database Operations**: Data storage operations\n",
    "- **ðŸŒ¸ AI Sub-tasks**: LLM-powered sub-operations within composite tasks\n",
    "- **ðŸŸ¢ Parallel Processing**: Batch execution for performance\n",
    "\n",
    "### Key Implementation Details\n",
    "\n",
    "1. **LangGraph Framework**: Uses `@task` decorators and `@entrypoint` for workflow orchestration\n",
    "2. **Composite Tasks**: `generate_employee` and `generate_department` encapsulate multiple operations\n",
    "3. **Parallel Execution**: Employee generation processes in batches of 5 for performance\n",
    "4. **Job Management**: Job roles are added to database before employee generation\n",
    "5. **AI Integration**: Uses GPT-4o for company specs and GPT-5-nano for employee details\n",
    "6. **Memory Management**: InMemorySaver checkpointer for workflow state persistence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add project root in the path\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "import mlflow\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from src.dataset.workflow import dataset_workflow\n",
    "\n",
    "\n",
    "project_root = pathlib.Path().resolve().parent.parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(str(project_root / '.env'))\n",
    "\n",
    "mlflow.openai.autolog()\n",
    "mlflow.langchain.autolog()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Run AI Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "brief_description = (\n",
    "    'A global retail and wholesale enterprise that operates a diverse '\n",
    "    \"network of physical stores and digital platforms. The company's activities span three main divisions: \"\n",
    "    'its domestic retail operations, international markets, and membership-based wholesale clubs. '\n",
    "    'The company also has a shared services division that provides centralized corporate functions such as HR, Finance, IT, etc. '\n",
    "    'Its store formats include large-scale supercenters, supermarkets, warehouse clubs, cash-and-carry outlets, '\n",
    "    'and discount stores. In addition to its brick-and-mortar presence, it runs multiple eCommerce platforms and '\n",
    "    'mobile applications across different countries, including regional online marketplaces and digital payment services. '\n",
    "    \"The company's offerings cover a broad range of consumer needs, with a particular strength in groceries, \"\n",
    "    'everyday essentials, and general merchandise.'\n",
    ")\n",
    "\n",
    "config = {'configurable': {'thread_id': '1'}}\n",
    "\n",
    "\n",
    "counter = 0\n",
    "for step in dataset_workflow.stream(input=brief_description, config=config, stream_mode='tasks'):\n",
    "    counter += 1\n",
    "    print(f'Step {counter} - {step}', end='\\r')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
