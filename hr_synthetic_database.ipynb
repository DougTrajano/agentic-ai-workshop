{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# HR Synthetic Database Generator - Agentic Workflow\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/DougTrajano/agentic-ai-workshop/blob/main/hr_synthetic_database.ipynb)\n",
    "\n",
    "This Jupyter Notebook demonstrates how to generate a synthetic HR database based on a company description provided by the user using Agentic Workflow.\n",
    "\n",
    "The dataset generation workflow follows these main phases:\n",
    "\n",
    "1. **Company Specification**: Convert user input into a structured company specification using LLM.\n",
    "2. **Demographic Ratios**: Generate demographic ratios based on company characteristics using LLM.\n",
    "3. **Database Setup**: Create the database structure with HR schema.\n",
    "4. **Business Unit Processing**: For each business unit:\n",
    "   - Add business unit and director job to database.\n",
    "   - Generate director employee (including education, compensation, and storage).\n",
    "   - Process all departments within the business unit.\n",
    "5. **Department Processing**: For each department:\n",
    "   - Add department and all job roles to database.\n",
    "   - Generate department employees in parallel batches (manager + staff).\n",
    "   - Each employee generation includes education determination, compensation calculation, and database storage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Set up Environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Install Dependencies\n",
    "\n",
    "In this section, we will install all necessary dependencies required for the notebook to run successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q pydantic==2.11 pydantic-settings==2.11 \\\n",
    "    duckdb>=1.3 faker>=37.12 datasets>=4.0 huggingface_hub>=0.35 \\\n",
    "        langchain>=1.0 langchain-openai>=1.0 langgraph>=1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Define Parameters\n",
    "\n",
    "We'll configure the path where our DuckDB database will be stored. This local database will hold all the generated HR data including employees, departments, jobs, and compensation information.\n",
    "\n",
    "The environment variables include the OpenAI API and Hugging Face credentials needed for the notebook to function properly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import Field, SecretStr\n",
    "from pydantic_settings import BaseSettings\n",
    "\n",
    "\n",
    "class Settings(BaseSettings):\n",
    "    \"\"\"Agentic Workflow settings.\"\"\"\n",
    "\n",
    "    OPENAI_API_KEY: SecretStr = Field(\n",
    "        ...,\n",
    "        description='API key for OpenAI services.'\n",
    "    )\n",
    "\n",
    "    HF_TOKEN: SecretStr = Field(\n",
    "        ...,\n",
    "        description='Hugging Face API token for accessing models and datasets.'\n",
    "    )\n",
    "\n",
    "    DUCKDB_PATH: str = Field(\n",
    "        './data/hr_database.duckdb',\n",
    "        description='Path to the DuckDB database file.'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "# Detect if running on Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "# Load environment variables based on environment\n",
    "if IN_COLAB:\n",
    "    # Running on Google Colab - use userdata\n",
    "    from google.colab import userdata\n",
    "\n",
    "    os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
    "    os.environ['HF_TOKEN'] = userdata.get('HF_TOKEN')\n",
    "\n",
    "\n",
    "settings = Settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Define Database Schema\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Data Models\n",
    "\n",
    "We'll define the data models representing the HR database schema using Pydantic for type-safe, validated data structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import uuid\n",
    "from enum import Enum, StrEnum\n",
    "from typing import List, Optional\n",
    "\n",
    "from pydantic import BaseModel, Field, computed_field, field_validator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "#### Common Fields\n",
    "\n",
    "Define base classes that will be inherited by other models:\n",
    "\n",
    "- **BaseFields**: Provides auto-generated unique identifiers (UUID) for all entities\n",
    "- **StartAndEndDates**: Adds start/end date fields with validation for time-bound entities like contracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseFields(BaseModel):\n",
    "    \"\"\"Base fields providing a unique identifier for all models.\n",
    "\n",
    "    This base class ensures every model in the HR system has a consistent\n",
    "    unique identifier that is automatically generated using UUID1.\n",
    "    \"\"\"\n",
    "\n",
    "    id: uuid.UUID = Field(\n",
    "        default_factory=uuid.uuid1,\n",
    "        description='Auto-generated unique identifier'\n",
    "    )\n",
    "\n",
    "\n",
    "class StartAndEndDates(BaseModel):\n",
    "    \"\"\"Mixin for models that require time-bound validity periods.\n",
    "\n",
    "    This mixin provides start and end date fields with validation to ensure\n",
    "    logical date ordering. Useful for contracts, employment periods, and\n",
    "    other time-limited entities.\n",
    "    \"\"\"\n",
    "\n",
    "    start_date: datetime.date = Field(..., description='Start date')\n",
    "    end_date: Optional[datetime.date] = Field(None, description='End date')\n",
    "\n",
    "    @field_validator('end_date')\n",
    "    @classmethod\n",
    "    def validate_end_date(cls, v, values):\n",
    "        \"\"\"Ensure end date is after start date.\n",
    "\n",
    "        Args:\n",
    "            v: The end_date value being validated\n",
    "            values: Dictionary containing other field values\n",
    "\n",
    "        Returns:\n",
    "            datetime.date: The validated end_date\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If end_date is before or equal to start_date\n",
    "        \"\"\"\n",
    "        if v and 'start_date' in values and v <= values['start_date']:\n",
    "            raise ValueError('End date must be after start date')\n",
    "        return v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "#### Company Models\n",
    "\n",
    "Define the core company organizational models:\n",
    "\n",
    "- **Job**: Represents a position with level, family, contract type, and workplace arrangement\n",
    "- **Department**: A functional unit with a manager and specific job roles\n",
    "- **BusinessUnit**: A major division led by a director, containing multiple departments\n",
    "- **Company**: The complete organizational structure with industry classification and business units\n",
    "- **Ratios**: Demographic distribution ratios for generating diverse, realistic workforce composition\n",
    "\n",
    "These enums and models define the hierarchical structure and classifications used throughout the HR system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JobLevel(str, Enum):\n",
    "    \"\"\"Hierarchical job level classifications for career progression tracking.\n",
    "\n",
    "    Defines standardized levels that represent responsibility, experience,\n",
    "    and authority within the organizational structure, enabling clear\n",
    "    career pathing and compensation benchmarking.\n",
    "    \"\"\"\n",
    "\n",
    "    INTERN = 'Intern'\n",
    "    JUNIOR = 'Junior'\n",
    "    MID = 'Mid'\n",
    "    SENIOR = 'Senior'\n",
    "    LEAD = 'Lead'\n",
    "    MANAGER = 'Manager'\n",
    "    DIRECTOR = 'Director'\n",
    "    PRESIDENT = 'President'\n",
    "\n",
    "\n",
    "class JobFamily(str, Enum):\n",
    "    \"\"\"Functional job family classifications grouping related roles.\n",
    "\n",
    "    Organizes positions by functional area and skill set, facilitating\n",
    "    talent management, training programs, and career development within\n",
    "    similar discipline areas.\n",
    "    \"\"\"\n",
    "\n",
    "    ENGINEERING = 'Engineering'\n",
    "    PRODUCT = 'Product'\n",
    "    DESIGN = 'Design'\n",
    "    DATA = 'Data'\n",
    "    MARKETING = 'Marketing'\n",
    "    SALES = 'Sales'\n",
    "    CUSTOMER_SUCCESS = 'Customer Success'\n",
    "    FINANCE = 'Finance'\n",
    "    HUMAN_RESOURCES = 'Human Resources'\n",
    "    LEGAL = 'Legal'\n",
    "    OPERATIONS = 'Operations'\n",
    "    SECURITY = 'Security'\n",
    "    QUALITY_ASSURANCE = 'Quality Assurance'\n",
    "    BUSINESS_DEVELOPMENT = 'Business Development'\n",
    "    EXECUTIVE = 'Executive'\n",
    "\n",
    "\n",
    "class ContractType(str, Enum):\n",
    "    \"\"\"Employment contract classifications defining work arrangements.\n",
    "\n",
    "    Specifies the nature of the employment relationship, affecting benefits,\n",
    "    working hours, and legal obligations between employer and employee.\n",
    "    \"\"\"\n",
    "\n",
    "    FULL_TIME = 'Full-Time'\n",
    "    PART_TIME = 'Part-Time'\n",
    "    CONTRACT = 'Contract'\n",
    "    TEMPORARY = 'Temporary'\n",
    "    INTERN = 'Intern'\n",
    "\n",
    "\n",
    "class WorkplaceType(str, Enum):\n",
    "    \"\"\"Work location and arrangement classifications for modern workplace flexibility.\n",
    "\n",
    "    Defines where and how work is performed, supporting diverse work\n",
    "    arrangements and accommodating different employee preferences and\n",
    "    business needs.\n",
    "    \"\"\"\n",
    "\n",
    "    REMOTE = 'Remote'\n",
    "    ONSITE = 'Onsite'\n",
    "    HYBRID = 'Hybrid'\n",
    "\n",
    "\n",
    "class Job(BaseFields):\n",
    "    \"\"\"Complete job position specification within the organizational structure.\n",
    "\n",
    "    Defines a specific role with all its characteristics including level,\n",
    "    functional area, contract terms, and workplace arrangements. Used for\n",
    "    both organizational planning and employee assignment.\n",
    "    \"\"\"\n",
    "\n",
    "    name: str = Field(..., description='Job name')\n",
    "    description: Optional[str] = Field(None, description='A brief description of the job')\n",
    "    job_level: JobLevel = Field(..., description='Job level classification')\n",
    "    job_family: JobFamily = Field(..., description='Job family classification')\n",
    "    contract_type: ContractType = Field(..., description='Contract type')\n",
    "    workplace_type: WorkplaceType = Field(..., description='Type of workplace')\n",
    "\n",
    "\n",
    "class Industry(str, Enum):\n",
    "    \"\"\"Industry classifications for companies following standard industry categories.\n",
    "\n",
    "    These classifications align with common sector groupings used in business\n",
    "    and financial analysis, providing a standardized way to categorize companies\n",
    "    by their primary business focus.\n",
    "    \"\"\"\n",
    "\n",
    "    COMMUNICATION_SERVICES = 'Communication Services'\n",
    "    CONSULTING = 'Consulting'\n",
    "    CONSUMER_STAPLES = 'Consumer Staples'\n",
    "    EDUCATION = 'Education'\n",
    "    ENERGY = 'Energy'\n",
    "    FINANCIALS = 'Financials'\n",
    "    HEALTHCARE = 'Healthcare'\n",
    "    INDUSTRIALS = 'Industrials'\n",
    "    REAL_ESTATE = 'Real Estate'\n",
    "    RETAIL = 'Retail'\n",
    "    TECHNOLOGY = 'Technology'\n",
    "    UTILITIES = 'Utilities'\n",
    "\n",
    "\n",
    "class Department(BaseFields):\n",
    "    \"\"\"Specification for a department within a company's organizational structure.\n",
    "\n",
    "    Departments represent functional units within business units, each with a\n",
    "    designated manager and a specific set of job roles with defined headcounts.\n",
    "    This model is used for organizational planning and synthetic data generation.\n",
    "    \"\"\"\n",
    "\n",
    "    name: str = Field(..., description='Department name')\n",
    "    description: Optional[str] = Field(None, description='Department description')\n",
    "    manager: Job = Field(..., description='Manager of the department')\n",
    "    jobs: List['JobsSpec'] = Field(\n",
    "        ..., description='List of jobs and their headcount in this department'\n",
    "    )\n",
    "\n",
    "    class JobsSpec(BaseModel):\n",
    "        \"\"\"Specification for job distribution and headcount planning within a department.\n",
    "\n",
    "        Defines the relationship between specific job types and their planned\n",
    "        headcount allocation, enabling precise workforce planning and\n",
    "        organizational structure modeling.\n",
    "        \"\"\"\n",
    "\n",
    "        job: Job = Field(..., description='Job specification')\n",
    "        headcount: int = Field(..., ge=1, description='Planned headcount for job')\n",
    "\n",
    "\n",
    "class BusinessUnit(BaseFields):\n",
    "    \"\"\"Specification for a business unit within a company's organizational hierarchy.\n",
    "\n",
    "    Business units represent major operational divisions within a company,\n",
    "    each led by a director and containing multiple departments. This structure\n",
    "    enables clear accountability and management hierarchy modeling.\n",
    "    \"\"\"\n",
    "\n",
    "    name: str = Field(..., description='Business unit name')\n",
    "    description: Optional[str] = Field(None, description='Business unit description')\n",
    "    director: Job = Field(..., description='Director of the business unit')\n",
    "    departments: List[Department] = Field(\n",
    "        ..., description='List of departments within the business unit'\n",
    "    )\n",
    "\n",
    "\n",
    "class Company(BaseFields):\n",
    "    \"\"\"Complete specification for a company structure.\n",
    "\n",
    "    This model guides the synthetic data generation process by defining\n",
    "    the company's structure, demographics, and workforce composition.\n",
    "    \"\"\"\n",
    "\n",
    "    name: str = Field(..., description='Company name')\n",
    "    description: Optional[str] = Field(None, description='Company description')\n",
    "    industry: Industry = Field(..., description='Industry classification')\n",
    "    business_units: List[BusinessUnit] = Field(\n",
    "        ..., description='List of business units within the company'\n",
    "    )\n",
    "\n",
    "\n",
    "class Ratios(BaseModel):\n",
    "    \"\"\"Demographic distribution ratios for workforce composition modeling.\n",
    "\n",
    "    This model defines the proportional representation of different demographic\n",
    "    groups within a company's workforce. All ratios should sum to 1.0 within\n",
    "    each category and use 2 decimal places for precision in synthetic data generation.\n",
    "    \"\"\"\n",
    "\n",
    "    gender: 'GenderRatios' = Field(..., description='Proportion of employees by gender')\n",
    "    ethnicity: 'EthnicityRatios' = Field(..., description='Proportion of employees by ethnicity')\n",
    "    generation: 'GenerationRatios' = Field(\n",
    "        ..., description='Proportion of employees by generation'\n",
    "    )\n",
    "\n",
    "    class GenderRatios(BaseModel):\n",
    "        \"\"\"Proportional distribution of employees by gender identity.\n",
    "\n",
    "        Represents the workforce composition across different gender identities,\n",
    "        supporting inclusive demographic modeling. All ratios should sum to 1.0.\n",
    "        \"\"\"\n",
    "\n",
    "        MALE: float = Field(..., ge=0, le=1, description='Proportion of male employees')\n",
    "        FEMALE: float = Field(..., ge=0, le=1, description='Proportion of female employees')\n",
    "        NON_BINARY: float = Field(\n",
    "            ..., ge=0, le=1, description='Proportion of non-binary employees'\n",
    "        )\n",
    "        PREFER_NOT_TO_SAY: float = Field(\n",
    "            ..., ge=0, le=1, description='Proportion of employees who prefer not to say'\n",
    "        )\n",
    "\n",
    "    class EthnicityRatios(BaseModel):\n",
    "        \"\"\"Proportional distribution of employees by ethnic background.\n",
    "\n",
    "        Represents workforce diversity across major ethnic categories,\n",
    "        enabling realistic demographic modeling. All ratios should sum to 1.0.\n",
    "        \"\"\"\n",
    "\n",
    "        WHITE: float = Field(..., ge=0, le=1, description='Proportion of white employees')\n",
    "        BLACK: float = Field(..., ge=0, le=1, description='Proportion of black employees')\n",
    "        ASIAN: float = Field(..., ge=0, le=1, description='Proportion of Asian employees')\n",
    "        HISPANIC: float = Field(..., ge=0, le=1, description='Proportion of Hispanic employees')\n",
    "        OTHER: float = Field(\n",
    "            ..., ge=0, le=1, description='Proportion of employees from other ethnicities'\n",
    "        )\n",
    "\n",
    "    class GenerationRatios(BaseModel):\n",
    "        \"\"\"Proportional distribution of employees by generational cohorts.\n",
    "\n",
    "        Represents the age distribution of the workforce using standard\n",
    "        generational categories. Enables modeling of generational diversity\n",
    "        and workplace dynamics. All ratios should sum to 1.0.\n",
    "        \"\"\"\n",
    "\n",
    "        BABY_BOOMER: float = Field(\n",
    "            ..., ge=0, le=1, description='Proportion of Baby Boomer employees'\n",
    "        )\n",
    "\n",
    "        GEN_X: float = Field(..., ge=0, le=1, description='Proportion of Gen X employees')\n",
    "\n",
    "        MILLENNIAL: float = Field(\n",
    "            ..., ge=0, le=1, description='Proportion of Millennial employees'\n",
    "        )\n",
    "\n",
    "        GEN_Z: float = Field(..., ge=0, le=1, description='Proportion of Gen Z employees')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "#### Compensation Models\n",
    "\n",
    "Define the compensation model that captures employee pay structure:\n",
    "\n",
    "- **RateType**: Whether the employee is paid hourly or on salary\n",
    "- **Compensation**: Complete compensation package including base salary, bonuses, and commissions\n",
    "\n",
    "The model automatically calculates total compensation by summing all components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RateType(str, Enum):\n",
    "    \"\"\"Classification of compensation payment structures.\n",
    "\n",
    "    Defines whether an employee is paid on an hourly basis or receives\n",
    "    a fixed annual salary, affecting how compensation is calculated\n",
    "    and administered.\n",
    "    \"\"\"\n",
    "\n",
    "    HOURLY = 'Hourly'\n",
    "    SALARY = 'Salary'\n",
    "\n",
    "\n",
    "class Compensation(BaseFields):\n",
    "    \"\"\"The compensation package information for an employee.\"\"\"\n",
    "\n",
    "    annual_base_salary: float = Field(..., ge=1, description='Base annual salary')\n",
    "    annual_bonus_amount: float | None = Field(None, ge=0, description='Annual bonus amount')\n",
    "    annual_commission_amount: float | None = Field(\n",
    "        None, ge=0, description='Annual commission amount (usually a percentage of sales)'\n",
    "    )\n",
    "\n",
    "    rate_type: RateType = Field(..., description='Type of compensation rate')\n",
    "\n",
    "    @property\n",
    "    def total_compensation(self) -> float:\n",
    "        \"\"\"Calculate the total annual compensation including all components.\n",
    "\n",
    "        Returns:\n",
    "            float: Sum of base salary, bonus amount, and commission amount.\n",
    "                   None values are treated as zero in the calculation.\n",
    "        \"\"\"\n",
    "        return (\n",
    "            self.annual_base_salary\n",
    "            + (self.annual_bonus_amount or 0)\n",
    "            + (self.annual_commission_amount or 0)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "#### Employee Models\n",
    "\n",
    "Define the employee model and related demographic classifications:\n",
    "\n",
    "- **Gender, Ethnicity, Generation**: Demographic categories for workforce diversity\n",
    "- **EducationLevel, EducationField**: Academic qualifications and areas of study\n",
    "- **Employee**: Complete employee record with demographics, education, and organizational placement\n",
    "\n",
    "The Employee model includes computed properties that automatically generate realistic names and determine generational cohort based on birth date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "\n",
    "\n",
    "faker = Faker()\n",
    "\n",
    "\n",
    "class Gender(StrEnum):\n",
    "    \"\"\"Gender identity classifications supporting inclusive workforce representation.\n",
    "\n",
    "    Provides comprehensive gender categories that respect individual identity\n",
    "    while enabling demographic analysis and reporting.\n",
    "    \"\"\"\n",
    "\n",
    "    MALE = 'Male'\n",
    "    FEMALE = 'Female'\n",
    "    NON_BINARY = 'Non-binary'\n",
    "    PREFER_NOT_TO_SAY = 'Prefer not to say'\n",
    "\n",
    "\n",
    "class Ethnicity(StrEnum):\n",
    "    \"\"\"Ethnic background classifications for workforce diversity tracking.\n",
    "\n",
    "    Enables demographic analysis and diversity reporting while respecting\n",
    "    individual backgrounds and promoting inclusive workplace practices.\n",
    "    \"\"\"\n",
    "\n",
    "    ASIAN = 'Asian'\n",
    "    BLACK = 'Black'\n",
    "    HISPANIC = 'Hispanic'\n",
    "    WHITE = 'White'\n",
    "    OTHER = 'Other'\n",
    "\n",
    "\n",
    "class Generation(StrEnum):\n",
    "    \"\"\"Generational cohort classifications based on birth year ranges.\n",
    "\n",
    "    Categorizes employees into standard generational groups for analyzing\n",
    "    workplace dynamics, communication preferences, and career development needs.\n",
    "    \"\"\"\n",
    "\n",
    "    BABY_BOOMER = 'Baby Boomer'\n",
    "    GEN_X = 'Generation X'\n",
    "    MILLENNIAL = 'Millennial'\n",
    "    GEN_Z = 'Generation Z'\n",
    "\n",
    "\n",
    "class EducationLevel(StrEnum):\n",
    "    \"\"\"Academic achievement levels for skills and qualification assessment.\n",
    "\n",
    "    Represents the highest level of formal education completed, used for\n",
    "    job matching, career development, and compensation analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    HIGH_SCHOOL = 'High School'\n",
    "    ASSOCIATE = 'Associate Degree'\n",
    "    BACHELORS = 'Bachelor Degree'\n",
    "    MASTERS = 'Master Degree'\n",
    "    DOCTORATE = 'Doctorate'\n",
    "\n",
    "\n",
    "class EducationField(StrEnum):\n",
    "    \"\"\"Academic discipline classifications for specialized knowledge assessment.\n",
    "\n",
    "    Comprehensive categorization of fields of study that enables skills\n",
    "    matching, career pathing, and department alignment based on educational\n",
    "    background and expertise areas.\n",
    "    \"\"\"\n",
    "\n",
    "    AGRICULTURE = 'Agriculture'\n",
    "    ARTS = 'Arts'\n",
    "    BIOLOGICAL_SCIENCES = 'Biological Sciences'\n",
    "    BUSINESS = 'Business & Management'\n",
    "    COMMUNICATION_MEDIA = 'Communication, Journalism & Media'\n",
    "    COMPUTER_SCIENCE = 'Computer Science'\n",
    "    CIVIL_ENGINEERING = 'Civil Engineering'\n",
    "    ELECTRICAL_ENGINEERING = 'Electrical Engineering'\n",
    "    MECHANICAL_ENGINEERING = 'Mechanical Engineering'\n",
    "    CHEMICAL_ENGINEERING = 'Chemical Engineering'\n",
    "    BIOMEDICAL_ENGINEERING = 'Biomedical Engineering'\n",
    "    MATERIALS_ENGINEERING = 'Materials Engineering'\n",
    "    ECONOMICS = 'Economics'\n",
    "    HEALTH_SCIENCES = 'Health Sciences'\n",
    "    LAW = 'Law'\n",
    "    LITERATURE = 'Literature'\n",
    "    MATHEMATICS_STATISTICS = 'Mathematics & Statistics'\n",
    "    MEDICINE = 'Medicine'\n",
    "    MILITARY_SCIENCE = 'Military Science'\n",
    "    NURSING = 'Nursing'\n",
    "    PEDAGOGY = 'Pedagogy'\n",
    "    PHARMACY = 'Pharmacy'\n",
    "    PHYSICAL_SCIENCES = 'Physics & Chemistry'\n",
    "    POLITICAL_SCIENCE = 'Political Science'\n",
    "    PSYCHOLOGY = 'Psychology'\n",
    "    RELIGIOUS_STUDIES = 'Religious Studies'\n",
    "    SOCIAL_SCIENCES = 'Social Sciences'\n",
    "\n",
    "\n",
    "class Employee(BaseFields):\n",
    "    \"\"\"Comprehensive employee record containing all personal and professional information.\n",
    "\n",
    "    This model serves as the central employee data structure, linking together\n",
    "    demographic information, educational background, and organizational placement.\n",
    "    Used for both synthetic data generation and real HR system modeling.\n",
    "    \"\"\"\n",
    "\n",
    "    job_id: uuid.UUID = Field(..., description='Job ID')\n",
    "    department_id: Optional[uuid.UUID] = Field(None, description='Department ID')\n",
    "    business_unit_id: Optional[uuid.UUID] = Field(None, description='Business Unit ID')\n",
    "    birth_date: datetime.date = Field(..., description='Date of birth')\n",
    "    gender: Gender = Field(..., description='Gender identification')\n",
    "    ethnicity: Ethnicity = Field(..., description='Ethnicity identification')\n",
    "    education_level: Optional[EducationLevel] = Field(\n",
    "        None, description='Highest education level completed'\n",
    "    )\n",
    "\n",
    "    education_field: Optional[EducationField] = Field(\n",
    "        None, description='Field of study for the employee'\n",
    "    )\n",
    "\n",
    "    @computed_field\n",
    "    @property\n",
    "    def first_name(self) -> str:\n",
    "        \"\"\"Generate an appropriate first name based on the employee's gender.\n",
    "\n",
    "        Uses Faker library to generate culturally appropriate names that\n",
    "        align with the employee's gender identity for realistic data modeling.\n",
    "\n",
    "        Returns:\n",
    "            str: A generated first name appropriate for the employee's gender\n",
    "        \"\"\"\n",
    "        if self.gender == Gender.MALE:\n",
    "            return faker.first_name_male()\n",
    "        elif self.gender == Gender.FEMALE:\n",
    "            return faker.first_name_female()\n",
    "        else:\n",
    "            return faker.first_name()\n",
    "\n",
    "    @computed_field\n",
    "    @property\n",
    "    def last_name(self) -> str:\n",
    "        \"\"\"Generate an appropriate last name based on the employee's gender.\n",
    "\n",
    "        Uses Faker library to generate culturally appropriate surnames that\n",
    "        align with the employee's gender identity for consistent data modeling.\n",
    "\n",
    "        Returns:\n",
    "            str: A generated last name appropriate for the employee's gender\n",
    "        \"\"\"\n",
    "        if self.gender == Gender.MALE:\n",
    "            return faker.last_name_male()\n",
    "        elif self.gender == Gender.FEMALE:\n",
    "            return faker.last_name_female()\n",
    "        else:\n",
    "            return faker.last_name()\n",
    "\n",
    "    @computed_field\n",
    "    @property\n",
    "    def generation(self) -> Generation:\n",
    "        \"\"\"Automatically determine generational cohort based on birth date.\n",
    "\n",
    "        Uses standard generational date ranges to classify employees into\n",
    "        appropriate cohorts for workplace analysis and management strategies.\n",
    "\n",
    "        Returns:\n",
    "            Generation: The generational category based on birth year\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If birth date falls outside recognized generational ranges\n",
    "        \"\"\"\n",
    "        if self.birth_date < datetime.date(1965, 1, 1):\n",
    "            return Generation.BABY_BOOMER\n",
    "        elif self.birth_date < datetime.date(1981, 1, 1):\n",
    "            return Generation.GEN_X\n",
    "        elif self.birth_date < datetime.date(1997, 1, 1):\n",
    "            return Generation.MILLENNIAL\n",
    "        elif self.birth_date < datetime.date(2016, 1, 1):\n",
    "            return Generation.GEN_Z\n",
    "        else:\n",
    "            raise ValueError('Unknown generation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### Database Class\n",
    "\n",
    "Create the Database class that provides an opinionated interface for interacting with DuckDB:\n",
    "\n",
    "- **create_tables()**: Initialize the database schema with all HR tables and relationships\n",
    "- **add_employee()**: Insert employee records with automatic UUID conflict resolution\n",
    "- **add_business_unit()**: Store business unit information\n",
    "- **add_department()**: Store department information linked to business units\n",
    "- **add_job()**: Store job specifications\n",
    "- **add_compensation()**: Store compensation packages linked to employees\n",
    "\n",
    "The database enforces referential integrity through foreign key constraints and ensures data consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import duckdb\n",
    "\n",
    "\n",
    "class Database:\n",
    "    \"\"\"Database interface for DuckDB.\n",
    "\n",
    "    Provides a database abstraction layer for managing HR entities\n",
    "    including employees, business units, departments, jobs, and compensation\n",
    "    records. Uses DuckDB for efficient analytical queries and data processing.\n",
    "\n",
    "    Attributes:\n",
    "        file_path (str): Path to the DuckDB database file\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, file_path: str = './data/hr_database.duckdb'):\n",
    "        \"\"\"Initialize the database connection with the specified file path.\n",
    "\n",
    "        Args:\n",
    "            file_path (str): Path to the DuckDB database file.\n",
    "                Directory will be created if it doesn't exist.\n",
    "                Defaults to \"./data/hr_database.duckdb\"\n",
    "        \"\"\"\n",
    "        self.file_path = file_path\n",
    "        os.makedirs(os.path.dirname(self.file_path), exist_ok=True)\n",
    "\n",
    "    def create_tables(self):\n",
    "        \"\"\"Create the complete HR database schema with all necessary tables.\n",
    "\n",
    "        Creates tables for business_units, departments, jobs, employees, and\n",
    "        compensations with proper foreign key relationships and constraints.\n",
    "        This method is idempotent and safe to call multiple times.\n",
    "\n",
    "        Tables created:\n",
    "        - business_units: Top-level organizational divisions\n",
    "        - departments: Functional units within business units\n",
    "        - jobs: Job position definitions and classifications\n",
    "        - employees: Employee personal and demographic information\n",
    "        - compensations: Employee compensation packages and amounts\n",
    "        \"\"\"\n",
    "        with duckdb.connect(self.file_path) as con:\n",
    "            # Create business_units table\n",
    "            con.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS business_units (\n",
    "                    id VARCHAR PRIMARY KEY,\n",
    "                    name VARCHAR NOT NULL,\n",
    "                    description VARCHAR,\n",
    "                    director_job_id VARCHAR NOT NULL\n",
    "                );\n",
    "            \"\"\")\n",
    "\n",
    "            # Create departments table\n",
    "            con.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS departments (\n",
    "                    id VARCHAR PRIMARY KEY,\n",
    "                    name VARCHAR NOT NULL,\n",
    "                    description VARCHAR,\n",
    "                    manager_job_id VARCHAR NOT NULL,\n",
    "                    business_unit_id VARCHAR NOT NULL,\n",
    "                    FOREIGN KEY (business_unit_id) REFERENCES business_units(id)\n",
    "                );\n",
    "            \"\"\")\n",
    "\n",
    "            # Create jobs table\n",
    "            con.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS jobs (\n",
    "                    id VARCHAR PRIMARY KEY,\n",
    "                    name VARCHAR NOT NULL,\n",
    "                    description VARCHAR,\n",
    "                    job_level VARCHAR NOT NULL,\n",
    "                    job_family VARCHAR NOT NULL,\n",
    "                    contract_type VARCHAR NOT NULL,\n",
    "                    workplace_type VARCHAR NOT NULL\n",
    "                );\n",
    "            \"\"\")\n",
    "\n",
    "            # Create employees table\n",
    "            con.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS employees (\n",
    "                    id VARCHAR PRIMARY KEY,\n",
    "                    job_id VARCHAR NOT NULL,\n",
    "                    department_id VARCHAR,\n",
    "                    business_unit_id VARCHAR,\n",
    "                    first_name VARCHAR NOT NULL,\n",
    "                    last_name VARCHAR NOT NULL,\n",
    "                    birth_date DATE NOT NULL,\n",
    "                    gender VARCHAR NOT NULL,\n",
    "                    ethnicity VARCHAR NOT NULL,\n",
    "                    education_level VARCHAR,\n",
    "                    education_field VARCHAR,\n",
    "                    generation VARCHAR NOT NULL,\n",
    "                    FOREIGN KEY (job_id) REFERENCES jobs(id),\n",
    "                    FOREIGN KEY (department_id) REFERENCES departments(id),\n",
    "                    FOREIGN KEY (business_unit_id) REFERENCES business_units(id)\n",
    "                );\n",
    "            \"\"\")\n",
    "\n",
    "            # Create compensation table\n",
    "            con.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS compensations (\n",
    "                    id VARCHAR PRIMARY KEY,\n",
    "                    employee_id VARCHAR NOT NULL,\n",
    "                    annual_base_salary DECIMAL(12,2) NOT NULL,\n",
    "                    annual_bonus_amount DECIMAL(12,2),\n",
    "                    annual_commission_amount DECIMAL(12,2),\n",
    "                    rate_type VARCHAR NOT NULL,\n",
    "                    total_compensation DECIMAL(12,2) NOT NULL,\n",
    "                    FOREIGN KEY (employee_id) REFERENCES employees(id)\n",
    "                );\n",
    "            \"\"\")\n",
    "\n",
    "    def add_employee(self, employee: Employee):\n",
    "        \"\"\"Insert a new employee record into the database.\n",
    "\n",
    "        Stores complete employee information including demographics, education,\n",
    "        and organizational assignments. Automatically handles UUID conversion\n",
    "        and enum value extraction.\n",
    "\n",
    "        Args:\n",
    "            employee (Employee): Employee model instance containing all\n",
    "                               required employee information\n",
    "\n",
    "        Note:\n",
    "            Either department_id or business_unit_id must be set, but not both,\n",
    "            as enforced by the database constraint.\n",
    "        \"\"\"\n",
    "        with duckdb.connect(self.file_path) as con:\n",
    "            while True:\n",
    "                try:\n",
    "                    con.execute(\n",
    "                        \"\"\"\n",
    "                        INSERT INTO employees (\n",
    "                            id, job_id, department_id, business_unit_id, first_name, last_name,\n",
    "                            birth_date, gender, ethnicity, education_level,\n",
    "                            education_field, generation\n",
    "                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "                    \"\"\",\n",
    "                        (\n",
    "                            str(employee.id),\n",
    "                            str(employee.job_id),\n",
    "                            str(employee.department_id) if employee.department_id else None,\n",
    "                            str(employee.business_unit_id) if employee.business_unit_id else None,\n",
    "                            employee.first_name,\n",
    "                            employee.last_name,\n",
    "                            employee.birth_date,\n",
    "                            employee.gender.value,\n",
    "                            employee.ethnicity.value,\n",
    "                            employee.education_level.value if employee.education_level else None,\n",
    "                            employee.education_field.value if employee.education_field else None,\n",
    "                            employee.generation.value,\n",
    "                        ),\n",
    "                    )\n",
    "                except duckdb.ConstraintException as e:\n",
    "                    print(\n",
    "                        f'Failed to add employee {employee.first_name} {employee.last_name}: {e}'\n",
    "                    )\n",
    "                    # Regenerate UUID and retry\n",
    "                    employee.id = uuid.uuid1()\n",
    "                    continue\n",
    "                break\n",
    "\n",
    "    def add_business_unit(self, business_unit: BusinessUnit):\n",
    "        \"\"\"Insert a new business unit record into the database.\n",
    "\n",
    "        Creates a business unit entry with its associated director job\n",
    "        reference. The director job should be added separately using add_job().\n",
    "\n",
    "        Args:\n",
    "            business_unit (BusinessUnit): Business unit model instance with\n",
    "                                        name, description, and director information\n",
    "        \"\"\"\n",
    "        with duckdb.connect(self.file_path) as con:\n",
    "            con.execute(\n",
    "                \"\"\"\n",
    "                INSERT INTO business_units (id, name, description, director_job_id)\n",
    "                VALUES (?, ?, ?, ?)\n",
    "            \"\"\",\n",
    "                (\n",
    "                    str(business_unit.id),\n",
    "                    business_unit.name,\n",
    "                    business_unit.description,\n",
    "                    str(business_unit.director.id),\n",
    "                ),\n",
    "            )\n",
    "\n",
    "    def add_department(self, department: Department, business_unit_id: str):\n",
    "        \"\"\"Insert a new department record linked to its parent business unit.\n",
    "\n",
    "        Creates a department entry with its manager job reference and business\n",
    "        unit association. The manager job should be added separately using add_job().\n",
    "\n",
    "        Args:\n",
    "            department (Department): Department model instance with name,\n",
    "                                   description, and manager information\n",
    "            business_unit_id (str): UUID string of the parent business unit\n",
    "        \"\"\"\n",
    "        with duckdb.connect(self.file_path) as con:\n",
    "            con.execute(\n",
    "                \"\"\"\n",
    "                INSERT INTO departments (id, name, description, manager_job_id, business_unit_id)\n",
    "                VALUES (?, ?, ?, ?, ?)\n",
    "            \"\"\",\n",
    "                (\n",
    "                    str(department.id),\n",
    "                    department.name,\n",
    "                    department.description,\n",
    "                    str(department.manager.id),\n",
    "                    business_unit_id,\n",
    "                ),\n",
    "            )\n",
    "\n",
    "    def add_job(self, job: Job):\n",
    "        \"\"\"Insert a new job position record into the database.\n",
    "\n",
    "        Stores complete job specification including level, family, contract\n",
    "        type, and workplace arrangement. Automatically handles enum value\n",
    "        extraction for database storage.\n",
    "\n",
    "        Args:\n",
    "            job (Job): Job model instance containing position details,\n",
    "                      classifications, and work arrangements\n",
    "        \"\"\"\n",
    "        with duckdb.connect(self.file_path) as con:\n",
    "            con.execute(\n",
    "                \"\"\"\n",
    "                INSERT INTO jobs (\n",
    "                    id, name, description, job_level, job_family,\n",
    "                    contract_type, workplace_type\n",
    "                ) VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "            \"\"\",\n",
    "                (\n",
    "                    str(job.id),\n",
    "                    job.name,\n",
    "                    job.description,\n",
    "                    job.job_level.value,\n",
    "                    job.job_family.value,\n",
    "                    job.contract_type.value,\n",
    "                    job.workplace_type.value,\n",
    "                ),\n",
    "            )\n",
    "\n",
    "    def add_compensation(self, compensation: Compensation, employee_id: str):\n",
    "        \"\"\"Insert a compensation record linked to an employee.\n",
    "\n",
    "        Stores complete compensation package including base salary, bonuses,\n",
    "        and commissions. Automatically calculates and stores total compensation.\n",
    "\n",
    "        Args:\n",
    "            compensation (Compensation): Compensation model instance with\n",
    "                                       salary and benefit information\n",
    "            employee_id (str): UUID string of the associated employee\n",
    "        \"\"\"\n",
    "        with duckdb.connect(self.file_path) as con:\n",
    "            while True:\n",
    "                try:\n",
    "                    con.execute(\n",
    "                        \"\"\"\n",
    "                        INSERT INTO compensations (\n",
    "                            id, employee_id, annual_base_salary, annual_bonus_amount,\n",
    "                            annual_commission_amount, rate_type, total_compensation\n",
    "                        ) VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "                    \"\"\",\n",
    "                        (\n",
    "                            str(compensation.id),\n",
    "                            employee_id,\n",
    "                            compensation.annual_base_salary,\n",
    "                            compensation.annual_bonus_amount,\n",
    "                            compensation.annual_commission_amount,\n",
    "                            compensation.rate_type.value,\n",
    "                            compensation.total_compensation,\n",
    "                        ),\n",
    "                    )\n",
    "                except duckdb.ConstraintException as e:\n",
    "                    print(f'Failed to add compensation for employee {employee_id}: {e}')\n",
    "                    # Regenerate UUID and retry\n",
    "                    compensation.id = uuid.uuid1()\n",
    "                    continue\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Define Helper Functions\n",
    "\n",
    "Define helper functions for generating realistic demographic data:\n",
    "\n",
    "- **get_birth_date()**: Generates random birth dates within appropriate year ranges for each generation\n",
    "- **weighted_random_choice()**: Selects items based on weighted probabilities to match demographic ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "# Set a fixed seed for reproducibility\n",
    "random.seed(1993)\n",
    "\n",
    "\n",
    "def get_birth_date(generation: Generation) -> datetime.date:\n",
    "    \"\"\"Generate a realistic birth date for the specified generational cohort.\n",
    "\n",
    "    Creates a random birth date within the standard year ranges for each\n",
    "    generation, ensuring demographic accuracy in synthetic data generation.\n",
    "    Uses a fixed random seed for reproducible results.\n",
    "\n",
    "    Args:\n",
    "        generation (Generation): The target generational cohort\n",
    "\n",
    "    Returns:\n",
    "        datetime.date: A randomly generated birth date within the appropriate\n",
    "                      year range for the specified generation\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If an invalid or unrecognized generation is provided\n",
    "\n",
    "    Note:\n",
    "        Generation year ranges:\n",
    "        - Baby Boomer: 1946-1964\n",
    "        - Generation X: 1965-1980\n",
    "        - Millennial: 1981-1996\n",
    "        - Generation Z: 1997-2012\n",
    "    \"\"\"\n",
    "    if generation == Generation.BABY_BOOMER:\n",
    "        start_year, end_year = 1946, 1964\n",
    "    elif generation == Generation.GEN_X:\n",
    "        start_year, end_year = 1965, 1980\n",
    "    elif generation == Generation.MILLENNIAL:\n",
    "        start_year, end_year = 1981, 1996\n",
    "    elif generation == Generation.GEN_Z:\n",
    "        start_year, end_year = 1997, 2012\n",
    "    else:\n",
    "        raise ValueError(f'Invalid generation: {generation}')\n",
    "\n",
    "    # Generate a random birth date within the range\n",
    "    birth_date = datetime.date(\n",
    "        year=random.randint(start_year, end_year),  # nosec B311\n",
    "        month=random.randint(1, 12),  # nosec B311\n",
    "        day=random.randint(1, 28),  # nosec B311\n",
    "    )\n",
    "\n",
    "    return birth_date\n",
    "\n",
    "\n",
    "def weighted_random_choice(choices: dict[Any, float]) -> Any:\n",
    "    \"\"\"Select an item from a weighted distribution using random sampling.\n",
    "\n",
    "    Implements weighted random selection where each choice has a probability\n",
    "    proportional to its weight. Uses cumulative distribution for efficient\n",
    "    selection, ensuring proper statistical distribution in synthetic data.\n",
    "\n",
    "    Args:\n",
    "        choices (dict[Any, float]): Dictionary mapping items to their weights.\n",
    "                                  Weights should be positive numbers and\n",
    "                                  don't need to sum to 1.0\n",
    "\n",
    "    Returns:\n",
    "        Any: The randomly selected item based on weighted probabilities\n",
    "\n",
    "    Example:\n",
    "        >>> choices = {'A': 0.7, 'B': 0.2, 'C': 0.1}\n",
    "        >>> result = weighted_random_choice(choices)\n",
    "        >>> # 'A' has 70% chance, 'B' has 20% chance, 'C' has 10% chance\n",
    "\n",
    "    Note:\n",
    "        Uses a fixed random seed (1993) for reproducible results across runs.\n",
    "        If weights don't sum exactly due to floating-point precision,\n",
    "        returns the last choice as fallback.\n",
    "    \"\"\"\n",
    "    total = sum(choices.values())\n",
    "    r = random.uniform(0, total)  # nosec B311\n",
    "    for item, weight in choices.items():\n",
    "        if r < weight:\n",
    "            return item\n",
    "        r -= weight\n",
    "    return list(choices.keys())[-1]  # Fallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Define Agentic Workflow\n",
    "\n",
    "In this section, we will implement our LangGraph-based Agentic Workflow for synthetic HR database generation.\n",
    "\n",
    "We will use the [LangGraph Functional API](https://docs.langchain.com/oss/python/langgraph/functional-api) to define tasks and orchestrate the workflow.\n",
    "\n",
    "The LangGraph Functional API uses two key building blocks:\n",
    "\n",
    "- `@entrypoint`  Marks a function as the starting point of a workflow, encapsulating logic and managing execution flow, including handling long-running tasks and interrupts.\n",
    "- `@task`  Represents a discrete unit of work, such as an API call or data processing step, that can be executed asynchronously within an entrypoint. Tasks return a future-like object that can be awaited or resolved synchronously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import batched\n",
    "\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.func import entrypoint, task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "#### Workflow tasks\n",
    "\n",
    "Define the individual tasks that make up our agentic workflow. Each task is decorated with `@task` to enable parallel execution and state management:\n",
    "\n",
    "**AI-Powered Generation Tasks:**\n",
    "- **get_company_spec()**: Transforms user input into a structured company specification using GPT-4o\n",
    "- **get_demographic_ratios()**: Generates realistic demographic distributions based on company characteristics\n",
    "- **get_education_fields()**: Determines appropriate education level and field for each employee role\n",
    "- **get_employee_compensation()**: Calculates realistic compensation packages based on role and qualifications\n",
    "\n",
    "**Database Operations:**\n",
    "- **create_database()**: Initializes the DuckDB database with the HR schema\n",
    "- **add_business_unit_to_db()**: Stores business unit and director job records\n",
    "- **add_department_to_db()**: Stores department, manager, and all job specifications\n",
    "- **add_employee_to_db()**: Stores employee and compensation records\n",
    "\n",
    "**Data Generation Orchestration:**\n",
    "- **generate_employee()**: Creates a complete employee record with education and compensation\n",
    "- **generate_department()**: Generates all employees for a department (manager + staff) in parallel batches\n",
    "\n",
    "These tasks work together to create a realistic, diverse HR database with proper organizational hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def get_company_spec(user_input: str) -> Company:\n",
    "    \"\"\"Generate a comprehensive company specification from natural language input.\n",
    "\n",
    "    Uses OpenAI Language Model to transform user requirements into a structured Company model\n",
    "    with complete organizational hierarchy including business units, departments,\n",
    "    and job positions. Ensures realistic and coherent organizational structure.\n",
    "\n",
    "    Args:\n",
    "        user_input (str): Natural language description of the desired company\n",
    "                         structure, industry, and characteristics\n",
    "\n",
    "    Returns:\n",
    "        Company: Structured company specification with business units,\n",
    "                departments, jobs, and leadership roles properly defined\n",
    "\n",
    "    Note:\n",
    "        The LLM is instructed to create realistic organizational hierarchies\n",
    "        with diverse names and common business structures.\n",
    "    \"\"\"\n",
    "    llm = ChatOpenAI(model='gpt-4o', timeout=600, max_retries=3)\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            SystemMessagePromptTemplate.from_template(\n",
    "                'You are an experienced business strategist specializing in creating '\n",
    "                'detailed organizational specifications from brief company descriptions.\\n\\n'\n",
    "                'Your task is to design a realistic company structure that includes:\\n\\n'\n",
    "                '- Business Units (based on product lines, regions, or functions).\\n\\n'\n",
    "                '- Departments within each business unit (e.g., HR, IT, Sales, Marketing, Finance, etc.).\\n\\n'\n",
    "                '- Key Roles and Jobs at different levels, ensuring diversity and realism in job titles and names.\\n\\n'\n",
    "                'Guidelines:\\n'\n",
    "                '- Each business unit should be led by a Director overseeing multiple departments.\\n\\n'\n",
    "                '- Each department should have a Manager and several distinct job roles across senior, mid-level, and junior positions.\\n\\n'\n",
    "                '- Use realistic and varied names for all business units, departments, and roles.\\n\\n'\n",
    "                '- Usually, a company has 3-5 business units, each with 3-7 departments, and each department with 3-10 job roles.\\n\\n'\n",
    "                '- Ensure the organizational hierarchy is coherent and reflects common corporate structures.'\n",
    "            ),\n",
    "            HumanMessagePromptTemplate.from_template('{text}'),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    chain = prompt | llm.with_structured_output(Company)\n",
    "\n",
    "    response = chain.invoke({'text': user_input})\n",
    "    return response\n",
    "\n",
    "\n",
    "@task\n",
    "def get_demographic_ratios(company_spec: Company) -> Ratios:\n",
    "    \"\"\"Generate realistic demographic distribution ratios for the company.\n",
    "\n",
    "    Analyzes the company specification and industry to create appropriate\n",
    "    demographic ratios that align with industry benchmarks and realistic\n",
    "    workforce distributions. Uses OpenAI Language Model for intelligent ratio generation.\n",
    "\n",
    "    Args:\n",
    "        company_spec (Company): The company specification containing industry,\n",
    "                               size, and organizational structure information\n",
    "\n",
    "    Returns:\n",
    "        Ratios: Demographic ratios for gender, ethnicity, and generation\n",
    "               distributions that reflect realistic workforce composition\n",
    "\n",
    "    Note:\n",
    "        The LLM considers industry standards and company characteristics\n",
    "        to generate statistically reasonable demographic distributions.\n",
    "    \"\"\"\n",
    "    llm = ChatOpenAI(model='gpt-4o', timeout=60, max_retries=3)\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            SystemMessagePromptTemplate.from_template(\n",
    "                'You are an expert at defining demographic ratios '\n",
    "                'based on the company specification and aligning with industry benchmarks.'\n",
    "            ),\n",
    "            HumanMessagePromptTemplate.from_template('{company_spec}'),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    chain = prompt | llm.with_structured_output(Ratios)\n",
    "\n",
    "    response = chain.invoke({'company_spec': company_spec.model_dump()})\n",
    "    return response\n",
    "\n",
    "\n",
    "@task\n",
    "def get_education_fields(employee: Employee, job: Job):\n",
    "    \"\"\"Determine appropriate education level and field for an employee's role.\n",
    "\n",
    "    Uses AI analysis to match employee demographics and job requirements\n",
    "    with realistic education credentials. Considers job family, level,\n",
    "    and industry standards to assign appropriate qualifications.\n",
    "\n",
    "    Args:\n",
    "        employee (Employee): Employee model with demographic information\n",
    "        job (Job): Job model with position requirements and classifications\n",
    "\n",
    "    Returns:\n",
    "        EducationFieldsResponse: Education level and field assignments\n",
    "                               that align with the job requirements\n",
    "    \"\"\"\n",
    "\n",
    "    class EducationFieldsResponse(BaseModel):\n",
    "        \"\"\"Generates education level and field of an employee.\"\"\"\n",
    "\n",
    "        education_level: EducationLevel = Field(\n",
    "            ..., description='The education level of the employee.'\n",
    "        )\n",
    "\n",
    "        education_field: EducationField = Field(\n",
    "            ..., description='The field of education of the employee.'\n",
    "        )\n",
    "\n",
    "    llm = ChatOpenAI(model='gpt-5-nano', timeout=20, max_retries=5)\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            SystemMessagePromptTemplate.from_template(\n",
    "                'You are an expert HR professional who determines '\n",
    "                'the education level and field of an employee based on their data and job role.'\n",
    "            ),\n",
    "            HumanMessagePromptTemplate.from_template(\n",
    "                \"\"\"{{\"employee\": \"{employee}\", \"job\": \"{job}\"}}\"\"\"\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    chain = prompt | llm.with_structured_output(EducationFieldsResponse)\n",
    "\n",
    "    response: EducationFieldsResponse = chain.invoke(\n",
    "        {'employee': employee.model_dump(), 'job': job.model_dump()}\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\n",
    "@task\n",
    "def get_employee_compensation(employee: Employee, job: Job) -> Compensation:\n",
    "    \"\"\"Calculate appropriate compensation package for an employee's position.\n",
    "\n",
    "    Analyzes employee qualifications, experience indicators, and job\n",
    "    characteristics to determine realistic compensation including base\n",
    "    salary, bonuses, and commissions. Considers market rates and internal equity.\n",
    "\n",
    "    Args:\n",
    "        employee (Employee): Employee model with demographics and education\n",
    "        job (Job): Job model with level, family, and workplace information\n",
    "\n",
    "    Returns:\n",
    "        Compensation: Complete compensation package with base salary,\n",
    "                     bonuses, and commission amounts appropriate for the role\n",
    "    \"\"\"\n",
    "    llm = ChatOpenAI(model='gpt-5-nano', timeout=20, max_retries=5)\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            SystemMessagePromptTemplate.from_template(\n",
    "                'You are an expert HR professional who determines '\n",
    "                'the compensation of an employee based on their data and job role.'\n",
    "            ),\n",
    "            HumanMessagePromptTemplate.from_template(\n",
    "                \"\"\"\n",
    "                {{\"employee\": \"{employee}\", \"job\": \"{job}\"}}\n",
    "                \"\"\"\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    chain = prompt | llm.with_structured_output(Compensation)\n",
    "\n",
    "    response = chain.invoke({'employee': employee.model_dump(), 'job': job.model_dump()})\n",
    "    return response\n",
    "\n",
    "\n",
    "@task\n",
    "def create_database() -> None:\n",
    "    \"\"\"Initialize a new DuckDB database with the complete HR schema.\n",
    "\n",
    "    Creates a fresh database instance with all necessary tables for storing\n",
    "    HR data including business units, departments, jobs, employees, and\n",
    "    compensation records. Sets up proper relationships and constraints.\n",
    "\n",
    "    Returns:\n",
    "        None: Database is created and initialized at the configured path\n",
    "\n",
    "    Note:\n",
    "        This operation is idempotent and safe to call multiple times.\n",
    "        Uses the default database path configured in the Database class.\n",
    "    \"\"\"\n",
    "    db = Database(file_path=settings.DUCKDB_PATH)\n",
    "    db.create_tables()\n",
    "\n",
    "\n",
    "@task\n",
    "def add_department_to_db(department: Department, business_unit_id: str):\n",
    "    \"\"\"Add a new department record to the database.\"\"\"\n",
    "    db = Database(file_path=settings.DUCKDB_PATH)\n",
    "\n",
    "    db.add_job(department.manager)\n",
    "\n",
    "    for job_spec in department.jobs:\n",
    "        db.add_job(job_spec.job)\n",
    "\n",
    "    db.add_department(department, business_unit_id)\n",
    "\n",
    "\n",
    "@task\n",
    "def add_business_unit_to_db(business_unit: BusinessUnit):\n",
    "    \"\"\"Add a new business unit record to the database.\"\"\"\n",
    "    db = Database(file_path=settings.DUCKDB_PATH)\n",
    "    db.add_job(business_unit.director)\n",
    "    db.add_business_unit(business_unit)\n",
    "\n",
    "\n",
    "@task\n",
    "def add_employee_to_db(employee: Employee, compensation: Compensation):\n",
    "    \"\"\"Add a new employee record to the database.\"\"\"\n",
    "    db = Database(file_path=settings.DUCKDB_PATH)\n",
    "    db.add_employee(employee)\n",
    "    db.add_compensation(compensation, str(employee.id))\n",
    "\n",
    "\n",
    "@task\n",
    "def generate_employee(\n",
    "    job: Job,\n",
    "    birth_date: datetime.date,\n",
    "    gender: Gender,\n",
    "    ethnicity: Ethnicity,\n",
    "    department_id: Optional[uuid.UUID] = None,\n",
    "    business_unit_id: Optional[uuid.UUID] = None,\n",
    "):\n",
    "    \"\"\"Generate employee records based on job specification and demographic ratios.\n",
    "\n",
    "    The records will be added in the database.\n",
    "    \"\"\"\n",
    "    employee = Employee(\n",
    "        job_id=job.id,\n",
    "        department_id=department_id,\n",
    "        business_unit_id=business_unit_id,\n",
    "        birth_date=birth_date,\n",
    "        gender=gender,\n",
    "        ethnicity=ethnicity,\n",
    "        education_level=None,\n",
    "        education_field=None,\n",
    "    )\n",
    "\n",
    "    education_fields = get_education_fields(employee, job).result()\n",
    "    employee.education_level = education_fields.education_level\n",
    "    employee.education_field = education_fields.education_field\n",
    "\n",
    "    compensation = get_employee_compensation(employee, job).result()\n",
    "\n",
    "    add_employee_to_db(employee, compensation).result()\n",
    "\n",
    "\n",
    "@task\n",
    "def generate_department(\n",
    "    department: Department, ratios: Ratios, business_unit_id: uuid.UUID | None = None\n",
    "):\n",
    "    \"\"\"Generate department records based on department specification and demographic ratios.\n",
    "\n",
    "    The records will be added in the database.\n",
    "    \"\"\"\n",
    "    # manager is human too\n",
    "    generate_employee(\n",
    "        job=department.manager,\n",
    "        department_id=department.id,\n",
    "        business_unit_id=business_unit_id,\n",
    "        birth_date=get_birth_date(\n",
    "            Generation[weighted_random_choice(ratios.generation.model_dump())]\n",
    "        ),\n",
    "        gender=Gender[weighted_random_choice(ratios.gender.model_dump())],\n",
    "        ethnicity=Ethnicity[weighted_random_choice(ratios.ethnicity.model_dump())],\n",
    "    ).result()\n",
    "\n",
    "    for job_spec in department.jobs:\n",
    "        # Parallel execution with batching\n",
    "        for batch in batched(range(job_spec.headcount), n=5):\n",
    "            futures = [\n",
    "                generate_employee(\n",
    "                    job=job_spec.job,\n",
    "                    department_id=department.id,\n",
    "                    business_unit_id=business_unit_id,\n",
    "                    birth_date=get_birth_date(\n",
    "                        Generation[weighted_random_choice(ratios.generation.model_dump())]\n",
    "                    ),\n",
    "                    gender=Gender[weighted_random_choice(ratios.gender.model_dump())],\n",
    "                    ethnicity=Ethnicity[weighted_random_choice(ratios.ethnicity.model_dump())],\n",
    "                )\n",
    "                for _ in batch\n",
    "            ]\n",
    "\n",
    "            _ = [future.result() for future in futures]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "#### Workflow entrypoint\n",
    "\n",
    "Define the main workflow entrypoint that orchestrates the entire dataset generation process:\n",
    "\n",
    "The `dataset_workflow()` function coordinates all tasks in the correct sequence:\n",
    "\n",
    "1. **Specification Phase**: Convert user input to structured company spec and generate demographic ratios\n",
    "2. **Database Setup**: Create the database schema\n",
    "3. **Hierarchical Generation**: For each business unit:\n",
    "   - Add the business unit and director job to database\n",
    "   - Generate the director employee record\n",
    "   - For each department:\n",
    "     - Add department and all job roles\n",
    "     - Generate department employees (manager + staff) in parallel batches\n",
    "\n",
    "The workflow uses **InMemorySaver** for checkpointing, allowing for state recovery and debugging.\n",
    "\n",
    "All employee generation respects the demographic ratios to ensure realistic diversity throughout the organization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = InMemorySaver()\n",
    "\n",
    "\n",
    "@entrypoint(checkpointer=checkpointer)\n",
    "def dataset_workflow(user_input: str) -> str:\n",
    "    \"\"\"Complete AI-powered workflow for generating synthetic HR datasets.\n",
    "\n",
    "    Orchestrates the end-to-end process of transforming user requirements\n",
    "    into a fully populated HR database with realistic employee data.\n",
    "    Combines AI-driven specification generation with systematic data creation.\n",
    "\n",
    "    Args:\n",
    "        user_input (str): Natural language description of the desired\n",
    "                         company structure, industry, and characteristics\n",
    "\n",
    "    Returns:\n",
    "        str: Completion message with database information\n",
    "\n",
    "    Workflow Steps:\n",
    "        1. Generate company specification from user input\n",
    "        2. Create demographic ratios based on company characteristics\n",
    "        3. Initialize database with proper schema\n",
    "        4. Generate business units and their directors\n",
    "        5. Create departments with managers and employees\n",
    "        6. Assign education and compensation to all employees\n",
    "\n",
    "    Note:\n",
    "        Uses LangGraph checkpointing for workflow state management and\n",
    "        recovery. Ensures consistent demographic distributions across\n",
    "        all generated employees.\n",
    "    \"\"\"\n",
    "    company = get_company_spec(user_input).result()\n",
    "    ratios = get_demographic_ratios(company).result()\n",
    "\n",
    "    db_name = create_database().result()\n",
    "\n",
    "    for business_unit in company.business_units:\n",
    "        # Add business unit to database\n",
    "        add_business_unit_to_db(business_unit).result()\n",
    "\n",
    "        # Add director as employee\n",
    "        generate_employee(\n",
    "            job=business_unit.director,\n",
    "            business_unit_id=business_unit.id,\n",
    "            birth_date=get_birth_date(\n",
    "                Generation[weighted_random_choice(ratios.generation.model_dump())]\n",
    "            ),\n",
    "            gender=Gender[weighted_random_choice(ratios.gender.model_dump())],\n",
    "            ethnicity=Ethnicity[weighted_random_choice(ratios.ethnicity.model_dump())],\n",
    "        ).result()\n",
    "\n",
    "        # Add departments and their employees\n",
    "        for department in business_unit.departments:\n",
    "            add_department_to_db(department, str(business_unit.id)).result()\n",
    "            generate_department(department, ratios, business_unit.id).result()\n",
    "\n",
    "    return f'Dataset generation completed. Database: {db_name}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "## Run Agentic Workflow\n",
    "\n",
    "Execute the agentic workflow with a sample company description.\n",
    "\n",
    "This example creates a global retail and wholesale enterprise with:\n",
    "\n",
    "- Multiple business units (domestic retail, international, wholesale clubs, shared services)\n",
    "- Various store formats (supercenters, warehouse clubs, discount stores)\n",
    "- Both physical and digital operations (brick-and-mortar + eCommerce)\n",
    "- Comprehensive product offerings (groceries, essentials, general merchandise)\n",
    "\n",
    "The workflow will:\n",
    "\n",
    "1. Generate a complete organizational structure with realistic business units and departments\n",
    "2. Create hundreds or thousands of employee records with diverse demographics\n",
    "3. Assign appropriate education credentials and compensation to each employee\n",
    "4. Store everything in a queryable DuckDB database\n",
    "\n",
    "The streaming output shows progress as each task completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "\n",
    "# Anonymized Walmart description ;)\n",
    "brief_description = \"\"\"\\\n",
    "A global retail and wholesale enterprise that operates a diverse network of physical stores and digital platforms. \\\n",
    "The company's activities span three main divisions: its domestic retail operations, international markets, and membership-based wholesale clubs. \\\n",
    "The company also has a shared services division that provides centralized corporate functions such as HR, Finance, IT, etc. \\\n",
    "Its store formats include large-scale supercenters, supermarkets, warehouse clubs, cash-and-carry outlets, and discount stores. \\\n",
    "In addition to its brick-and-mortar presence, it runs multiple eCommerce platforms and mobile applications across different countries, \\\n",
    "including regional online marketplaces and digital payment services. \\\n",
    "The company's offerings cover a broad range of consumer needs, with a particular strength in groceries, everyday essentials, and general merchandise.\n",
    "\"\"\"\n",
    "\n",
    "config = RunnableConfig(configurable={'thread_id': '1'})\n",
    "\n",
    "\n",
    "counter = 0\n",
    "for step in dataset_workflow.stream(input=brief_description, config=config, stream_mode='tasks'):\n",
    "    counter += 1\n",
    "    print(f'\\rStep {counter} - {step}', end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "## Hugging Face Dataset\n",
    "\n",
    "In this section, we will format the generated database into a Hugging Face dataset and push it to the Hugging Face Hub for easy access and sharing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "### Format Database as HF Dataset\n",
    "\n",
    "Extract data from the DuckDB database and convert it into a Hugging Face DatasetDict.\n",
    "\n",
    "This process:\n",
    "\n",
    "1. Connects to the generated DuckDB database in read-only mode\n",
    "2. Queries each table (business_units, departments, jobs, employees, compensations)\n",
    "3. Converts each table to a pandas DataFrame\n",
    "4. Creates a Hugging Face Dataset from each DataFrame\n",
    "5. Combines them into a DatasetDict with named splits\n",
    "\n",
    "The resulting dataset structure provides easy access to all HR data and shows the record counts for each table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "\n",
    "with duckdb.connect(settings.DUCKDB_PATH, read_only=True) as con:\n",
    "    # Read each table into a pandas DataFrame\n",
    "    business_units_df = con.execute('SELECT * FROM business_units').df()\n",
    "    departments_df = con.execute('SELECT * FROM departments').df()\n",
    "    jobs_df = con.execute('SELECT * FROM jobs').df()\n",
    "    employees_df = con.execute('SELECT * FROM employees').df()\n",
    "    compensations_df = con.execute('SELECT * FROM compensations').df()\n",
    "\n",
    "# Convert DataFrames to Hugging Face Datasets\n",
    "hf_dataset = DatasetDict(\n",
    "    {\n",
    "        'business_units': Dataset.from_pandas(business_units_df),\n",
    "        'departments': Dataset.from_pandas(departments_df),\n",
    "        'jobs': Dataset.from_pandas(jobs_df),\n",
    "        'employees': Dataset.from_pandas(employees_df),\n",
    "        'compensations': Dataset.from_pandas(compensations_df),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Display dataset info\n",
    "print('Dataset structure:')\n",
    "print(hf_dataset)\n",
    "\n",
    "print('\\nSample counts:')\n",
    "for split_name, dataset in hf_dataset.items():\n",
    "    print(f'  {split_name}: {len(dataset)} records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "### Push to Hugging Face Hub\n",
    "\n",
    "Upload the formatted dataset to the Hugging Face Hub for easy sharing and access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'dougtrajano/hr-synthetic-database'\n",
    "\n",
    "# Push to Hugging Face Hub\n",
    "for split_name, dataset in hf_dataset.items():\n",
    "    dataset.push_to_hub(\n",
    "        repo_id=dataset_name,\n",
    "        config_name=str(split_name),\n",
    "    )\n",
    "\n",
    "print(f'Dataset successfully pushed to: https://huggingface.co/datasets/{dataset_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "##  Agentic Workflow Complete!\n",
    "\n",
    "The synthetic HR database has been successfully generated and is ready for use.\n",
    "\n",
    "Users can access the dataset through the Hugging Face Hub at: [dougtrajano/hr-synthetic-database](https://huggingface.co/dougtrajano/hr-synthetic-database)\n",
    "\n",
    "We can now load the dataset directly using the `datasets` library:\n",
    "\n",
    "```python\n",
    "from datasets import load_dataset\n",
    "\n",
    "business_units = load_dataset('dougtrajano/hr-synthetic-database', 'business_units')\n",
    "departments = load_dataset('dougtrajano/hr-synthetic-database', 'departments')\n",
    "jobs = load_dataset('dougtrajano/hr-synthetic-database', 'jobs')\n",
    "employees = load_dataset('dougtrajano/hr-synthetic-database', 'employees')\n",
    "compensations = load_dataset('dougtrajano/hr-synthetic-database', 'compensations')\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
