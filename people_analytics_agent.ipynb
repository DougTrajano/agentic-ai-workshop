{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# People Analytics Agent - Agentic AI Workshop\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/DougTrajano/agentic-ai-workshop/blob/main/people_analytics_agent.ipynb)\n",
    "\n",
    "This Jupyter Notebook demonstrates how to build an intelligent People Analytics Agent using LangChain and Google's Gemini model.\n",
    "\n",
    "The agent can:\n",
    "- **Query HR databases** using natural language questions\n",
    "- **Execute SQL queries** automatically based on user requests\n",
    "- **Perform calculations** and statistical analysis\n",
    "- **Generate visualizations** using Plotly for data insights\n",
    "- **Provide structured responses** with summaries, SQL queries, datasets, and charts\n",
    "\n",
    "This notebook showcases an agentic workflow that combines SQL database interaction with AI-powered analysis to answer complex HR and people analytics questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Set up Environment\n",
    "\n",
    "### Install Dependencies\n",
    "\n",
    "Install all required Python packages for building the People Analytics Agent, including LangChain for agent orchestration, Google Generative AI for the LLM, and data manipulation libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q \"pydantic>=2.11\" \"pydantic-settings>=2.11\" \"faker>=37.12\" \\\n",
    "    \"datasets>=4.0\" \"huggingface_hub>=0.35\" \"sqlalchemy>=2.0.44\" \"sqlparse>=0.5\" \\\n",
    "        \"numexpr>=2.14\" \"numpy>=2.0\" \"pandas>=2.2\" \"plotly>=5.24\" \"langchain>=1.0\" \\\n",
    "            \"langgraph>=1.0\" \"langchain-community>=0.4\" \"langchain-google-genai>=3.0\" \\\n",
    "                \"chainlit>=2.8\" \"pyngrok>=7.4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db37a2e",
   "metadata": {},
   "source": [
    "### Define Parameters\n",
    "\n",
    "Configure the agent settings including:\n",
    "- **GOOGLE_API_KEY**: Authentication for Google AI Studio (Gemini models)\n",
    "- **HF_TOKEN**: Hugging Face authentication for accessing datasets\n",
    "- **HF_DATASET_NAME**: The synthetic HR database we generated in the previous notebook\n",
    "\n",
    "These parameters ensure secure access to both the AI model and the HR dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30c0d17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field, SecretStr, field_validator\n",
    "from pydantic_settings import BaseSettings\n",
    "\n",
    "\n",
    "class Settings(BaseSettings):\n",
    "    \"\"\"People Analytics Agent Settings.\"\"\"\n",
    "\n",
    "    GOOGLE_API_KEY: SecretStr = Field(\n",
    "        ...,\n",
    "        description=\"Google API key for accessing Google AI Studio.\",\n",
    "    )\n",
    "\n",
    "    HF_TOKEN: SecretStr = Field(\n",
    "        ...,\n",
    "        description=\"Hugging Face API token for accessing private resources.\",\n",
    "    )\n",
    "\n",
    "    HF_DATASET_NAME: str = Field(\n",
    "        default=\"dougtrajano/hr-synthetic-database\",\n",
    "        description=\"The name of the Hugging Face dataset to load.\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f15dc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "# Detect if running on Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "# Load environment variables based on environment\n",
    "if IN_COLAB:\n",
    "    # Running on Google Colab - use userdata\n",
    "    from google.colab import userdata\n",
    "\n",
    "    os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n",
    "    os.environ['HF_TOKEN'] = userdata.get('HF_TOKEN')\n",
    "\n",
    "\n",
    "settings = Settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21c76d3",
   "metadata": {},
   "source": [
    "## Load HR Synthetic Database\n",
    "\n",
    "Load the synthetic HR database that was generated in the `hr_synthetic_database.ipynb` notebook from Hugging Face Datasets.\n",
    "\n",
    "This dataset contains:\n",
    "- **business_units**: Top-level organizational divisions\n",
    "- **departments**: Functional units within business units\n",
    "- **jobs**: Job position definitions and classifications\n",
    "- **employees**: Employee personal and demographic information\n",
    "- **compensations**: Employee compensation packages\n",
    "\n",
    "We'll use the [load_dataset()](https://huggingface.co/docs/datasets/v4.3.0/en/package_reference/loading_methods#datasets.load_dataset) function from the [datasets](https://huggingface.co/docs/datasets/) library to load each table separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3832ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "business_units = load_dataset(settings.HF_DATASET_NAME, 'business_units')\n",
    "departments = load_dataset(settings.HF_DATASET_NAME, 'departments')\n",
    "jobs = load_dataset(settings.HF_DATASET_NAME, 'jobs')\n",
    "employees = load_dataset(settings.HF_DATASET_NAME, 'employees')\n",
    "compensations = load_dataset(settings.HF_DATASET_NAME, 'compensations')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b06b1fa",
   "metadata": {},
   "source": [
    "### Convert to Pandas DataFrames\n",
    "\n",
    "Convert the Hugging Face datasets to Pandas DataFrames for easier manipulation and loading into SQLite.\n",
    "\n",
    "We also clean the data by replacing Hugging Face's string representations of NULL values (like 'None' or empty strings) with proper `np.nan` values for correct database handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3dd115dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def clean_huggingface_nulls(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean Hugging Face dataset string representations of NULL values.\n",
    "\n",
    "    Hugging Face datasets may contain string 'None' or empty strings instead\n",
    "    of actual NULL values. This function replaces them with np.nan for proper\n",
    "    NULL handling in PostgreSQL.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input DataFrame with potential string NULL values.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Cleaned DataFrame with proper NULL values.\n",
    "    \"\"\"\n",
    "    df_clean = df.copy()\n",
    "    for col in df_clean.columns:\n",
    "        df_clean[col] = df_clean[col].replace(['None', ''], np.nan)\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3e252a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Business Units: (4, 4)\n",
      "Departments: (17, 5)\n",
      "Jobs: (94, 7)\n",
      "Employees: (15700, 12)\n",
      "Compensations: (15700, 7)\n"
     ]
    }
   ],
   "source": [
    "# Convert Hugging Face datasets to Pandas DataFrames\n",
    "df_business_units = clean_huggingface_nulls(\n",
    "    business_units['train'].to_pandas()\n",
    ")\n",
    "df_departments = clean_huggingface_nulls(\n",
    "    departments['train'].to_pandas()\n",
    ")\n",
    "df_jobs = clean_huggingface_nulls(\n",
    "    jobs['train'].to_pandas()\n",
    ")\n",
    "df_employees = clean_huggingface_nulls(\n",
    "    employees['train'].to_pandas()\n",
    ")\n",
    "df_compensations = clean_huggingface_nulls(\n",
    "    compensations['train'].to_pandas()\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Business Units: {df_business_units.shape}\")\n",
    "print(f\"Departments: {df_departments.shape}\")\n",
    "print(f\"Jobs: {df_jobs.shape}\")\n",
    "print(f\"Employees: {df_employees.shape}\")\n",
    "print(f\"Compensations: {df_compensations.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c54833e",
   "metadata": {},
   "source": [
    "### Load DataFrames into SQLite\n",
    "\n",
    "Create an in-memory SQLite database and load all HR tables into it.\n",
    "\n",
    "This approach provides:\n",
    "- **Fast querying**: In-memory databases offer excellent performance\n",
    "- **SQL compatibility**: Standard SQL interface for the agent to query\n",
    "- **No persistence needed**: Perfect for demo/workshop scenarios\n",
    "- **LangChain integration**: Works seamlessly with LangChain's SQL tools\n",
    "\n",
    "We also create a SQLAlchemy engine for compatibility with LangChain's SQL toolkit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "01490f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in SQLite:\n",
      "[('business_units',), ('departments',), ('jobs',), ('employees',), ('compensations',)]\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "\n",
    "# Create a SQLite file-based connection\n",
    "conn = sqlite3.connect('hr_synthetic_database.db', check_same_thread=False)\n",
    "\n",
    "# Create SQLAlchemy engine for the SQL toolkit\n",
    "db_engine = create_engine('sqlite:///hr_synthetic_database.db', creator=lambda: conn)\n",
    "\n",
    "# Create tables in SQLite from the DataFrames\n",
    "df_business_units.to_sql('business_units', conn, index=False, if_exists='replace')\n",
    "df_departments.to_sql('departments', conn, index=False, if_exists='replace')\n",
    "df_jobs.to_sql('jobs', conn, index=False, if_exists='replace')\n",
    "df_employees.to_sql('employees', conn, index=False, if_exists='replace')\n",
    "df_compensations.to_sql('compensations', conn, index=False, if_exists='replace')\n",
    "\n",
    "# Verify the tables were created\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "print(\"Tables in SQLite:\")\n",
    "print(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8bc4d8",
   "metadata": {},
   "source": [
    "## Build People Analytics Agent\n",
    "\n",
    "In this section, we'll construct our intelligent agent using LangChain's agent framework.\n",
    "\n",
    "The agent will combine:\n",
    "- **Language Model**: Google's Gemini for natural language understanding\n",
    "- **Tools**: SQL querying and mathematical calculations\n",
    "- **System Prompt**: Instructions for proper database interaction\n",
    "- **Structured Output**: Consistent response format with summaries and visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a01ecdc",
   "metadata": {},
   "source": [
    "### Load the Language Model\n",
    "\n",
    "Initialize Google's Gemini Flash model as our agent's reasoning engine.\n",
    "\n",
    "Gemini Flash offers:\n",
    "- **Fast inference**: Quick responses for interactive analysis\n",
    "- **Cost-effective**: Efficient for high-volume queries\n",
    "- **Strong reasoning**: Capable of complex SQL generation and data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d40b7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"models/gemini-flash-latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c05f72c",
   "metadata": {},
   "source": [
    "### Define Agent Tools\n",
    "\n",
    "Equip the agent with tools for data analysis and computation:\n",
    "\n",
    "1. **Calculator Tool**: Performs mathematical calculations using numexpr for statistical analysis\n",
    "2. **SQL Database Tools**: LangChain's SQL toolkit provides:\n",
    "   - `sql_db_list_tables`: List all available database tables\n",
    "   - `sql_db_schema`: Get table schemas and column information\n",
    "   - `sql_db_query`: Execute SQL queries and retrieve results\n",
    "   - `sql_db_query_checker`: Validate SQL syntax before execution\n",
    "\n",
    "These tools enable the agent to autonomously explore the database schema, construct appropriate SQL queries, and perform calculations on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ef4227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numexpr\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Calculate expression using Python's numexpr library.\n",
    "\n",
    "    Expression should be a single line mathematical expression\n",
    "    that solves the problem.\n",
    "\n",
    "    Examples:\n",
    "        \"37593 * 67\" for \"37593 times 67\"\n",
    "        \"37593**(1/5)\" for \"37593^(1/5)\"\n",
    "    \"\"\"\n",
    "    local_dict = {'pi': math.pi, 'e': math.e}\n",
    "    return str(\n",
    "        numexpr.evaluate(\n",
    "            expression.strip(),\n",
    "            global_dict={},  # restrict access to globals\n",
    "            local_dict=local_dict,  # add common mathematical functions\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18b3ad33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available tables: ['business_units', 'compensations', 'departments', 'employees', 'jobs']\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.agent_toolkits.sql.toolkit import SQLDatabaseToolkit\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "\n",
    "db = SQLDatabase(engine=db_engine)\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "sql_tools = toolkit.get_tools()\n",
    "\n",
    "print(f\"Available tables: {db.get_usable_table_names()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "abb1ef9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [calculator] + sql_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3231a707",
   "metadata": {},
   "source": [
    "### Define System Prompt\n",
    "\n",
    "Create the system prompt that guides the agent's behavior when interacting with the SQL database.\n",
    "\n",
    "The prompt instructs the agent to:\n",
    "- **Explore first**: Always check available tables and schemas before querying\n",
    "- **Write safe queries**: Create syntactically correct, read-only SQL (no DML operations)\n",
    "- **Limit results**: Return at most 5 results by default (configurable)\n",
    "- **Verify queries**: Double-check SQL before execution\n",
    "- **Handle errors**: Rewrite and retry queries if they fail\n",
    "- **Be efficient**: Only query relevant columns, not all columns\n",
    "\n",
    "This prompt ensures the agent follows best practices for database interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db87246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_system_prompt(dialect: str, top_k: int = 5) -> str:\n",
    "    \"\"\"Get the system prompt for the agent.\n",
    "\n",
    "    Args:\n",
    "        dialect (str): The SQL dialect of the database.\n",
    "        top_k (int): The maximum number of results to return.\n",
    "\n",
    "    Returns:\n",
    "        str: The system prompt.\n",
    "    \"\"\"\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "    You are an agent designed to interact with a SQL database.\n",
    "    Given an input question, create a syntactically correct {dialect} query to run,\n",
    "    then look at the results of the query and return the answer. Unless the user\n",
    "    specifies a specific number of examples they wish to obtain, always limit your\n",
    "    query to at most {top_k} results.\n",
    "\n",
    "    You can order the results by a relevant column to return the most interesting\n",
    "    examples in the database. Never query for all the columns from a specific table,\n",
    "    only ask for the relevant columns given the question.\n",
    "\n",
    "    You MUST double check your query before executing it. If you get an error while\n",
    "    executing a query, rewrite the query and try again.\n",
    "\n",
    "    DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the\n",
    "    database.\n",
    "\n",
    "    To start you should ALWAYS look at the tables in the database to see what you\n",
    "    can query. Do NOT skip this step.\n",
    "\n",
    "    Then you should query the schema of the most relevant tables.\n",
    "    \"\"\"\n",
    "\n",
    "    return system_prompt.format(\n",
    "        dialect=dialect,\n",
    "        top_k=top_k,\n",
    "    )\n",
    "\n",
    "\n",
    "system_prompt = get_system_prompt(dialect=db.dialect, top_k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd02173",
   "metadata": {},
   "source": [
    "### Define Response Format\n",
    "\n",
    "Define a structured output format using Pydantic to ensure consistent, high-quality agent responses.\n",
    "\n",
    "The `AgentOutput` model contains:\n",
    "- **summary**: Natural language answer with key findings and insights\n",
    "- **sql_query**: The SQL query executed (formatted for readability)\n",
    "- **dataset**: JSON representation of query results in pandas-compatible format\n",
    "- **plotly_json_fig**: Optional Plotly chart for data visualization\n",
    "\n",
    "This structure ensures every response is:\n",
    "- **Informative**: Contains both explanation and raw data\n",
    "- **Transparent**: Shows the SQL query used\n",
    "- **Visual**: Includes charts when appropriate\n",
    "- **Machine-readable**: JSON format for downstream processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ab0fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlparse\n",
    "\n",
    "\n",
    "class AgentOutput(BaseModel):\n",
    "    \"\"\"Agent response containing analysis summary, SQL query, dataset, and an optional Plotly JSON Chart.\"\"\"\n",
    "\n",
    "    summary: str = Field(\n",
    "        ...,\n",
    "        description=(\n",
    "            'Markdown-based short answer to the user question. '\n",
    "            \"Example: 'The Sales department has 150 employees.'\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    sql_query: str | None = Field(\n",
    "        default=None,\n",
    "        description=(\n",
    "            'SQL query executed to retrieve data. '\n",
    "            \"Example: 'SELECT AVG(Salary), MIN(Salary), MAX(Salary) FROM employees;'\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    dataset: str | None = Field(\n",
    "        default=None,\n",
    "        description=(\n",
    "            'A JSON-serializable representation of the dataset returned by the SQL query. '\n",
    "            'This should be compatible with pandas DataFrame construction (data and columns). '\n",
    "            'Include this field when the SQL query returns tabular data that supports the answer. '\n",
    "            'Example: \\'{\"data\": [[120000, 70000, 210000]], \"columns\": [\"average_salary\", \"min_salary\", \"max_salary\"]}\\''\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    plotly_json_fig: str | None = Field(\n",
    "        default=None,\n",
    "        description=(\n",
    "            'A Plotly JSON figure representation for visualizing the dataset. '\n",
    "            'Include this field when a graphical representation of the data is helpful. '\n",
    "            \"IMPORTANT: Always include data labels on the chart by setting 'text' in the trace \"\n",
    "            \"and 'textposition' to display values on the bars/points. \"\n",
    "            \"For bar charts, use 'textposition': 'auto' or 'outside'. \"\n",
    "            \"For scatter plots, use 'mode': 'markers+text'. \"\n",
    "            'Example: \\'{\"data\": [{\"type\": \"bar\", \"x\": [\"A\", \"B\"], \"y\": [10, 20], '\n",
    "            '\"text\": [10, 20], \"textposition\": \"auto\"}], '\n",
    "            '\"layout\": {\"title\": \"Sample Bar Chart\"}}\\''\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    @field_validator('sql_query')\n",
    "    @classmethod\n",
    "    def format_sql_query(cls, v: str | None) -> str | None:\n",
    "        \"\"\"Format SQL query by removing common leading whitespace.\"\"\"\n",
    "        if v is None:\n",
    "            return None\n",
    "        return sqlparse.format(v, reindent=True, keyword_case='upper', indent_width=4).strip()\n",
    "\n",
    "    def get_message(self) -> str:\n",
    "        \"\"\"Get a user-friendly message summarizing the agent's response.\"\"\"\n",
    "        message = self.summary\n",
    "        if self.sql_query:\n",
    "            message += f'\\n\\nSQL Query Executed:\\n```sql\\n{self.sql_query}\\n```'\n",
    "        return message\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759281c4",
   "metadata": {},
   "source": [
    "### Create the Agent\n",
    "\n",
    "Instantiate the LangChain agent with all components:\n",
    "- **Model**: Gemini Flash for reasoning and query generation\n",
    "- **Tools**: SQL database tools + calculator\n",
    "- **System Prompt**: Database interaction guidelines\n",
    "- **Response Format**: Structured output schema\n",
    "\n",
    "The agent uses a ReAct (Reasoning + Acting) pattern to:\n",
    "1. **Reason** about the user's question\n",
    "2. **Act** by using tools (query DB, calculate, etc.)\n",
    "3. **Observe** the results\n",
    "4. **Repeat** until the question is fully answered\n",
    "\n",
    "This creates an autonomous agent that can handle complex multi-step analytics questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "427c0254",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    system_prompt=system_prompt,\n",
    "    response_format=AgentOutput,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ccd536",
   "metadata": {},
   "source": [
    "### Test the Agent\n",
    "\n",
    "Run a test query to verify the agent is working correctly.\n",
    "\n",
    "This example asks the agent to \"show the number of employees by business unit\", which requires:\n",
    "1. **Discovering tables**: Agent explores the database schema\n",
    "2. **Understanding relationships**: Identifies the connection between employees and business_units\n",
    "3. **Writing SQL**: Constructs an appropriate GROUP BY query\n",
    "4. **Formatting output**: Returns results as a structured response with visualization\n",
    "\n",
    "The streaming output shows the agent's thought process and tool usage in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "64a280b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "show the number of employees by business unit\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_list_tables (78c6e216-02d4-4ae0-9af4-fa7d9c68460e)\n",
      " Call ID: 78c6e216-02d4-4ae0-9af4-fa7d9c68460e\n",
      "  Args:\n",
      "    tool_input:\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_list_tables\n",
      "\n",
      "business_units, compensations, departments, employees, jobs\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_schema (76dd605f-af47-4015-816a-f12a5699f737)\n",
      " Call ID: 76dd605f-af47-4015-816a-f12a5699f737\n",
      "  Args:\n",
      "    table_names: employees, business_units\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_schema\n",
      "\n",
      "\n",
      "CREATE TABLE business_units (\n",
      "\tid TEXT, \n",
      "\tname TEXT, \n",
      "\tdescription TEXT, \n",
      "\tdirector_job_id TEXT\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from business_units table:\n",
      "id\tname\tdescription\tdirector_job_id\n",
      "b1a0e1f2-1111-4c1a-9a10-0001d0b00101\tDomestic Retail Division\tOversees all retail formats in the home market, including supercenters, supermarkets, and discount s\td1b2c3d4-0001-4e01-9000-000000000001\n",
      "b1a0e1f2-2222-4c1a-9a10-0001d0b00102\tInternational Markets Division\tManages international retail formats and regional marketplaces in EMEA, APAC, and LATAM.\td1b2c3d4-0002-4e01-9000-000000000002\n",
      "ad21e882-b9e3-4200-8758-ba76115ee877\tMembership-Based Wholesale Club Division\tFocuses on operations and strategies for membership-based wholesale clubs and cash-and-carry operati\t6195c1ec-3eea-4a84-b2c8-b0a83770f6e0\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE employees (\n",
      "\tid TEXT, \n",
      "\tjob_id TEXT, \n",
      "\tdepartment_id TEXT, \n",
      "\tbusiness_unit_id TEXT, \n",
      "\tfirst_name TEXT, \n",
      "\tlast_name TEXT, \n",
      "\tbirth_date TEXT, \n",
      "\tgender TEXT, \n",
      "\tethnicity TEXT, \n",
      "\teducation_level TEXT, \n",
      "\teducation_field TEXT, \n",
      "\tgeneration TEXT\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from employees table:\n",
      "id\tjob_id\tdepartment_id\tbusiness_unit_id\tfirst_name\tlast_name\tbirth_date\tgender\tethnicity\teducation_level\teducation_field\tgeneration\n",
      "c7321b1a-91d9-11f0-87f9-e235d39662ee\td1b2c3d4-0001-4e01-9000-000000000001\tNone\tb1a0e1f2-1111-4c1a-9a10-0001d0b00101\tCarrie\tRomero\t2003-05-13\tFemale\tAsian\tMaster Degree\tBusiness & Management\tGeneration Z\n",
      "d220e7f4-91d9-11f0-87f9-e235d39662ee\td9a1a01a-0001-4a10-bb11-aaa000000001\tde9a1a01-1001-4a10-aaa1-0001d01a0001\tb1a0e1f2-1111-4c1a-9a10-0001d0b00101\tCarmen\tKlein\t2002-02-19\tFemale\tWhite\tBachelor Degree\tBusiness & Management\tGeneration Z\n",
      "dadcce08-91d9-11f0-87f9-e235d39662ee\ta0010a01-0001-4f01-9a01-01a000000001\tde9a1a01-1001-4a10-aaa1-0001d01a0001\tb1a0e1f2-1111-4c1a-9a10-0001d0b00101\tMichael\tSmith\t1994-08-05\tMale\tWhite\tBachelor Degree\tBusiness & Management\tMillennial\n",
      "*/\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_query_checker (9738f2d1-3aea-4db8-b49b-0b69d591a65f)\n",
      " Call ID: 9738f2d1-3aea-4db8-b49b-0b69d591a65f\n",
      "  Args:\n",
      "    query: SELECT T2.name, COUNT(T1.id) AS num_employees FROM employees AS T1 INNER JOIN business_units AS T2 ON T1.business_unit_id = T2.id GROUP BY T2.name ORDER BY num_employees DESC\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_query_checker\n",
      "\n",
      "SELECT T2.name, COUNT(T1.id) AS num_employees FROM employees AS T1 INNER JOIN business_units AS T2 ON T1.business_unit_id = T2.id GROUP BY T2.name ORDER BY num_employees DESC\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_query (f9c553f2-a439-443d-885e-989a12810b82)\n",
      " Call ID: f9c553f2-a439-443d-885e-989a12810b82\n",
      "  Args:\n",
      "    query: SELECT T2.name, COUNT(T1.id) AS num_employees FROM employees AS T1 INNER JOIN business_units AS T2 ON T1.business_unit_id = T2.id GROUP BY T2.name ORDER BY num_employees DESC\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_query\n",
      "\n",
      "[('Domestic Retail Division', 10795), ('International Markets Division', 4746), ('Membership-Based Wholesale Club Division', 93), ('Shared Services', 66)]\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: AgentOutput\n",
      "\n",
      "Returning structured response: summary='The number of employees by business unit is:\\n- Domestic Retail Division: 10,795 employees\\n- International Markets Division: 4,746 employees\\n- Membership-Based Wholesale Club Division: 93 employees\\n- Shared Services: 66 employees' sql_query='SELECT T2.name,\\n       COUNT(T1.id) AS num_employees\\nFROM employees AS T1\\nINNER JOIN business_units AS T2 ON T1.business_unit_id = T2.id\\nGROUP BY T2.name\\nORDER BY num_employees DESC' dataset='{\"data\": [[\"Domestic Retail Division\", 10795], [\"International Markets Division\", 4746], [\"Membership-Based Wholesale Club Division\", 93], [\"Shared Services\", 66]], \"columns\": [\"name\", \"num_employees\"]}' plotly_json_fig='{\"data\": [{\"type\": \"bar\", \"x\": [\"Domestic Retail Division\", \"International Markets Division\", \"Membership-Based Wholesale Club Division\", \"Shared Services\"], \"y\": [10795, 4746, 93, 66], \"text\": [10795, 4746, 93, 66], \"textposition\": \"auto\", \"marker\": {\"color\": [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\"]}}], \"layout\": {\"title\": \"Number of Employees by Business Unit\", \"xaxis\": {\"title\": \"Business Unit\"}, \"yaxis\": {\"title\": \"Number of Employees\"}}}'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"show the number of employees by business unit\",\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "user_config = RunnableConfig(\n",
    "    configurable={'thread_id': 'user_thread_id_1993'},\n",
    "    recursion_limit=40,\n",
    ")\n",
    "\n",
    "for step in agent.stream(inputs, config=user_config, stream_mode=\"values\"):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "487db463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Response:\n",
      "The number of employees by business unit is:\n",
      "- Domestic Retail Division: 10,795 employees\n",
      "- International Markets Division: 4,746 employees\n",
      "- Membership-Based Wholesale Club Division: 93 employees\n",
      "- Shared Services: 66 employees\n",
      "\n",
      "SQL Query Executed:\n",
      "```sql\n",
      "SELECT T2.name,\n",
      "       COUNT(T1.id) AS num_employees\n",
      "FROM employees AS T1\n",
      "INNER JOIN business_units AS T2 ON T1.business_unit_id = T2.id\n",
      "GROUP BY T2.name\n",
      "ORDER BY num_employees DESC\n",
      "```\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": [
           "#1f77b4",
           "#ff7f0e",
           "#2ca02c",
           "#d62728"
          ]
         },
         "text": [
          "10795",
          "4746",
          "93",
          "66"
         ],
         "textposition": "auto",
         "type": "bar",
         "x": [
          "Domestic Retail Division",
          "International Markets Division",
          "Membership-Based Wholesale Club Division",
          "Shared Services"
         ],
         "y": [
          10795,
          4746,
          93,
          66
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#f2f5fa"
            },
            "error_y": {
             "color": "#f2f5fa"
            },
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "baxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#506784"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "header": {
             "fill": {
              "color": "#2a3f5f"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#f2f5fa",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#f2f5fa"
          },
          "geo": {
           "bgcolor": "rgb(17,17,17)",
           "lakecolor": "rgb(17,17,17)",
           "landcolor": "rgb(17,17,17)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#506784"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "dark"
          },
          "paper_bgcolor": "rgb(17,17,17)",
          "plot_bgcolor": "rgb(17,17,17)",
          "polar": {
           "angularaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "radialaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "yaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "zaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#f2f5fa"
           }
          },
          "sliderdefaults": {
           "bgcolor": "#C8D4E3",
           "bordercolor": "rgb(17,17,17)",
           "borderwidth": 1,
           "tickwidth": 0
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "caxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "updatemenudefaults": {
           "bgcolor": "#506784",
           "borderwidth": 0
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Number of Employees by Business Unit"
        },
        "xaxis": {
         "title": {
          "text": "Business Unit"
         }
        },
        "yaxis": {
         "title": {
          "text": "Number of Employees"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.io as pio\n",
    "\n",
    "\n",
    "if \"structured_response\" in step:\n",
    "    response = AgentOutput.model_validate(step[\"structured_response\"])\n",
    "\n",
    "    print(f\"Agent Response:\\n{response.get_message()}\")\n",
    "\n",
    "    if response.plotly_json_fig:\n",
    "        fig = pio.from_json(response.plotly_json_fig, skip_invalid=True)\n",
    "        fig.update_layout(template='plotly_dark')\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2e4bb6",
   "metadata": {},
   "source": [
    "## Next Steps: Chainlit Integration\n",
    "\n",
    "The agent can be integrated with Chainlit to create an interactive conversational UI for People Analytics.\n",
    "\n",
    "Chainlit provides:\n",
    "- **Chat interface**: User-friendly UI for natural language queries\n",
    "- **Conversation history**: Maintains context across multiple questions\n",
    "- **Real-time streaming**: Shows agent progress as it thinks and acts\n",
    "- **Visualization support**: Renders Plotly charts inline\n",
    "\n",
    "This would enable HR professionals and analysts to interact with the HR database conversationally, asking follow-up questions and exploring data without writing SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd23fa6",
   "metadata": {},
   "source": [
    "### Write Chainlit App\n",
    "\n",
    "In the next cell, we will use the magic command `%%writefile app.py` to create a Chainlit application that leverages the People Analytics Agent we built in this notebook.\n",
    "\n",
    "This app will allow us to interact with the agent through a web-based chat interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a409c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile app.py\n",
    "import json\n",
    "import math\n",
    "\n",
    "import chainlit as cl\n",
    "import numexpr\n",
    "import pandas as pd\n",
    "import plotly.io as pio\n",
    "import sqlparse\n",
    "from langchain.agents import create_agent\n",
    "from langchain_community.agent_toolkits.sql.toolkit import SQLDatabaseToolkit\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langgraph.pregel import Pregel\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "\n",
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Calculate expression using Python's numexpr library.\n",
    "\n",
    "    Expression should be a single line mathematical expression\n",
    "    that solves the problem.\n",
    "\n",
    "    Examples:\n",
    "        \"37593 * 67\" for \"37593 times 67\"\n",
    "        \"37593**(1/5)\" for \"37593^(1/5)\"\n",
    "    \"\"\"\n",
    "    local_dict = {'pi': math.pi, 'e': math.e}\n",
    "    return str(\n",
    "        numexpr.evaluate(\n",
    "            expression.strip(),\n",
    "            global_dict={},  # restrict access to globals\n",
    "            local_dict=local_dict,  # add common mathematical functions\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "class AgentOutput(BaseModel):\n",
    "    \"\"\"Agent response containing analysis summary, SQL query, dataset, and an optional Plotly JSON Chart.\"\"\"\n",
    "\n",
    "    summary: str = Field(\n",
    "        ...,\n",
    "        description=(\n",
    "            'Markdown-based short answer to the user question. '\n",
    "            \"Example: 'The Sales department has 150 employees.'\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    sql_query: str | None = Field(\n",
    "        default=None,\n",
    "        description=(\n",
    "            'SQL query executed to retrieve data. '\n",
    "            \"Example: 'SELECT AVG(Salary), MIN(Salary), MAX(Salary) FROM employees;'\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    dataset: str | None = Field(\n",
    "        default=None,\n",
    "        description=(\n",
    "            'A JSON-serializable representation of the dataset returned by the SQL query. '\n",
    "            'This should be compatible with pandas DataFrame construction (data and columns). '\n",
    "            'Include this field when the SQL query returns tabular data that supports the answer. '\n",
    "            'Example: \\'{\"data\": [[120000, 70000, 210000]], \"columns\": [\"average_salary\", \"min_salary\", \"max_salary\"]}\\''\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    plotly_json_fig: str | None = Field(\n",
    "        default=None,\n",
    "        description=(\n",
    "            'A Plotly JSON figure representation for visualizing the dataset. '\n",
    "            'Include this field when a graphical representation of the data is helpful. '\n",
    "            \"IMPORTANT: Always include data labels on the chart by setting 'text' in the trace \"\n",
    "            \"and 'textposition' to display values on the bars/points. \"\n",
    "            \"For bar charts, use 'textposition': 'auto' or 'outside'. \"\n",
    "            \"For scatter plots, use 'mode': 'markers+text'. \"\n",
    "            'Example: \\'{\"data\": [{\"type\": \"bar\", \"x\": [\"A\", \"B\"], \"y\": [10, 20], '\n",
    "            '\"text\": [10, 20], \"textposition\": \"auto\"}], '\n",
    "            '\"layout\": {\"title\": \"Sample Bar Chart\"}}\\''\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "    @field_validator('sql_query')\n",
    "    @classmethod\n",
    "    def format_sql_query(cls, v: str | None) -> str | None:\n",
    "        \"\"\"Format SQL query by removing common leading whitespace.\"\"\"\n",
    "        if v is None:\n",
    "            return None\n",
    "        return sqlparse.format(v, reindent=True, keyword_case='upper', indent_width=4).strip()\n",
    "\n",
    "    def get_message(self) -> str:\n",
    "        \"\"\"Get a user-friendly message summarizing the agent's response.\"\"\"\n",
    "        message = self.summary\n",
    "        if self.sql_query:\n",
    "            message += f'\\n\\nSQL Query Executed:\\n```sql\\n{self.sql_query}\\n```'\n",
    "        return message\n",
    "\n",
    "\n",
    "def get_system_prompt(dialect: str, top_k: int = 5) -> str:\n",
    "    \"\"\"Get the system prompt for the agent.\n",
    "\n",
    "    Args:\n",
    "        dialect (str): The SQL dialect of the database.\n",
    "        top_k (int): The maximum number of results to return.\n",
    "\n",
    "    Returns:\n",
    "        str: The system prompt.\n",
    "    \"\"\"\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "    You are an agent designed to interact with a SQL database.\n",
    "    Given an input question, create a syntactically correct {dialect} query to run,\n",
    "    then look at the results of the query and return the answer. Unless the user\n",
    "    specifies a specific number of examples they wish to obtain, always limit your\n",
    "    query to at most {top_k} results.\n",
    "\n",
    "    You can order the results by a relevant column to return the most interesting\n",
    "    examples in the database. Never query for all the columns from a specific table,\n",
    "    only ask for the relevant columns given the question.\n",
    "\n",
    "    You MUST double check your query before executing it. If you get an error while\n",
    "    executing a query, rewrite the query and try again.\n",
    "\n",
    "    DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the\n",
    "    database.\n",
    "\n",
    "    To start you should ALWAYS look at the tables in the database to see what you\n",
    "    can query. Do NOT skip this step.\n",
    "\n",
    "    Then you should query the schema of the most relevant tables.\n",
    "    \"\"\"\n",
    "\n",
    "    return system_prompt.format(\n",
    "        dialect=dialect,\n",
    "        top_k=top_k,\n",
    "    )\n",
    "\n",
    "\n",
    "# Load LLM model\n",
    "llm = ChatGoogleGenerativeAI(model=\"models/gemini-flash-latest\")\n",
    "\n",
    "# Load SQLite database and get SQL toolkit\n",
    "db_engine = create_engine('sqlite:///hr_synthetic_database.db')\n",
    "db = SQLDatabase(engine=db_engine)\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "sql_tools = toolkit.get_tools()\n",
    "tools = [calculator] + sql_tools\n",
    "\n",
    "# Get system prompt\n",
    "system_prompt = get_system_prompt(dialect=db.dialect, top_k=5)\n",
    "\n",
    "\n",
    "@cl.set_starters\n",
    "async def set_starters(user: cl.User | None = None) -> list[cl.Starter]:\n",
    "    \"\"\"Set the starters for the chat application.\"\"\"\n",
    "    return [\n",
    "        cl.Starter(\n",
    "            label='Headcount by Business Unit',\n",
    "            message='Show me the headcount by business unit.',\n",
    "        ),\n",
    "        cl.Starter(\n",
    "            label='Headcount by Gender',\n",
    "            message='Show me the headcount by gender.',\n",
    "        ),\n",
    "        cl.Starter(\n",
    "            label='Headcount by Generation',\n",
    "            message='Show me the headcount by generation.',\n",
    "        ),\n",
    "        cl.Starter(\n",
    "            label='Average Salary by Job Title',\n",
    "            message='What is the average salary for each job title?',\n",
    "        ),\n",
    "        cl.Starter(\n",
    "            label='Total Compensation by Department',\n",
    "            message='What is the total compensation for each department?',\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "\n",
    "@cl.on_chat_start\n",
    "async def on_chat_start():\n",
    "    \"\"\"Handle the chat start event.\"\"\"\n",
    "    agent = create_agent(\n",
    "        model=llm,\n",
    "        tools=tools,\n",
    "        system_prompt=system_prompt,\n",
    "        response_format=AgentOutput,\n",
    "    )\n",
    "    cl.user_session.set('agent', agent)\n",
    "\n",
    "\n",
    "@cl.on_message\n",
    "async def on_message(msg: cl.Message):\n",
    "    \"\"\"Handle the message event.\"\"\"\n",
    "\n",
    "    # Load the agent from the user session\n",
    "    print('Retrieving agent from user session.')\n",
    "    agent = cl.user_session.get('agent')\n",
    "    if not isinstance(agent, Pregel):\n",
    "        print('Failed to retrieve a valid agent from user session.')\n",
    "        await cl.Message(content='Agent not initialized.').send()\n",
    "        raise ValueError('Agent not initialized.')\n",
    "\n",
    "    config = RunnableConfig(\n",
    "        configurable={'thread_id': cl.context.session.thread_id},\n",
    "        recursion_limit=40,\n",
    "        # callbacks=[cl.LangchainCallbackHandler()],\n",
    "    )\n",
    "\n",
    "    # Get response from the agent\n",
    "    print(\"Invoking agent with user's message.\")\n",
    "    response = agent.invoke({'messages': [HumanMessage(content=msg.content)]}, config=config)\n",
    "    print({'response': response})\n",
    "    response = AgentOutput.model_validate(response['structured_response'])\n",
    "\n",
    "    elements = []\n",
    "    if response.plotly_json_fig:\n",
    "        fig = pio.from_json(response.plotly_json_fig, skip_invalid=True)\n",
    "        fig.update_layout(template='plotly_dark')\n",
    "        elements.append(cl.Plotly(name='plot', figure=fig, display='inline'))\n",
    "    if response.dataset:\n",
    "        df = pd.DataFrame(**json.loads(response.dataset))\n",
    "        elements.append(cl.Dataframe(name='DataFrame', data=df, display='inline'))\n",
    "    print({\"elements\": elements})\n",
    "    await cl.Message(content=response.get_message(), elements=elements or None).send()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058dabfe",
   "metadata": {},
   "source": [
    "### Run Chainlit App\n",
    "\n",
    "In the next cell, we will run the Chainlit application using the command `chainlit run app.py -w`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c27ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!chainlit run app.py -w &>/content/logs.txt &"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee78f361",
   "metadata": {},
   "source": [
    "### Start pyngrok Tunnel\n",
    "\n",
    "With pyngrok, we can expose our local Chainlit app to the internet, allowing others to access it via a public URL.\n",
    "\n",
    "You need to replace the placeholder `YOUR_NGROK_AUTH_TOKEN` with your actual ngrok authentication token to enable the tunnel. \n",
    "\n",
    "To achieve this, access https://dashboard.ngrok.com/get-started/your-authtoken, sign up or log in, and copy your Authtoken.\n",
    "\n",
    "**Reference:** [Integration Examples - Google Colab  pyngrok documentation](https://pyngrok.readthedocs.io/en/latest/integrations.html#google-colaboratory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4a8667",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ngrok config add-authtoken YOUR_NGROK_AUTH_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8389c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyngrok import ngrok\n",
    "\n",
    "\n",
    "ngrok_tunnel = ngrok.connect(8000)\n",
    "print('Public URL:', ngrok_tunnel.public_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8414b355",
   "metadata": {},
   "source": [
    "### Kill ngrok Tunnel\n",
    "\n",
    "In the next cell, we will stop the ngrok tunnel to close public access to our Chainlit app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "137b35b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ngrok tunnel is still running.\n"
     ]
    }
   ],
   "source": [
    "# Get user confirmation before killing ngrok\n",
    "confirm = input(\"Are you sure you want to stop the ngrok tunnel? (yes/y): \")\n",
    "if confirm.lower() in ['yes', 'y']:\n",
    "    ngrok.kill()\n",
    "    print(\"Ngrok tunnel has been stopped.\")\n",
    "else:\n",
    "    print(\"Ngrok tunnel is still running.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853a8ef7",
   "metadata": {},
   "source": [
    "##  Lab Complete\n",
    "\n",
    "Congratulations! You've successfully completed the **People Analytics Agent** workshop! \n",
    "\n",
    "### What You've Accomplished\n",
    "\n",
    "Throughout this notebook, you've built a sophisticated AI-powered analytics system from scratch:\n",
    "\n",
    "-  **Loaded a synthetic HR database** with realistic employee, compensation, and organizational data\n",
    "-  **Created a SQLite database** optimized for fast querying and analysis\n",
    "-  **Built an intelligent agent** using LangChain and Google's Gemini model\n",
    "-  **Equipped the agent with tools** for SQL queries and mathematical calculations\n",
    "-  **Defined structured outputs** with summaries, SQL queries, datasets, and visualizations\n",
    "-  **Tested the agent** with real-world people analytics questions\n",
    "-  **Created a Chainlit web application** for interactive conversational analytics\n",
    "-  **Deployed the app** with ngrok for public access\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- **Agentic AI workflows** combine reasoning (LLMs) with actions (tools) to solve complex problems autonomously\n",
    "- **Structured outputs** ensure consistent, high-quality responses that combine explanation with data\n",
    "- **SQL + AI integration** enables natural language querying of databases without manual SQL writing\n",
    "- **Visualization integration** makes insights more accessible and actionable\n",
    "- **Interactive interfaces** (like Chainlit) democratize data analytics for non-technical users\n",
    "\n",
    "You now have the foundation to build intelligent data analysis agents for various domains beyond HRfrom finance to operations to customer analytics!\n",
    "\n",
    "Check out the [Governing AI Agents - DeepLearning.AI](https://www.deeplearning.ai/short-courses/governing-ai-agents/) course that also covers HR Analytics Agent in the Databricks ecosystem.\n",
    "\n",
    "**Well done! **"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01eee43a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
