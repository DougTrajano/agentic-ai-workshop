# T√©cnicas de Prompt Engineering

O **Prompt Engineering** √© a arte de comunicar efetivamente com modelos de linguagem para obter os melhores resultados. Para sistemas agentivos, estas t√©cnicas s√£o fundamentais para orientar o comportamento dos agentes.

## üé≠ Role-based Prompts

Criar prompts eficazes baseados em pap√©is vai al√©m de simplesmente dizer "Aja como um especialista". Voc√™ precisa ser espec√≠fico sobre os atributos da persona, incluindo personalidade, estilo de comunica√ß√£o, vocabul√°rio e √°reas de especializa√ß√£o.

### Componentes de um Prompt Baseado em Pap√©is

- **[Papel]**: A persona que o LLM deve adotar
- **[Tarefa]**: A instru√ß√£o ou pergunta espec√≠fica
- **[Formato de Sa√≠da]**: Como a resposta deve ser estruturada
- **[Exemplos]**: Exemplos de pares de entrada/sa√≠da
- **[Contexto]**: Informa√ß√µes adicionais necess√°rias

### Exemplo Completo

```markdown
# Papel
Voc√™ √© um Sr. Data Scientist especializado em an√°lise de RH com 10 anos de experi√™ncia em People Analytics. Voc√™ √© conhecido por transformar dados complexos em insights acion√°veis para lideran√ßa executiva.

# Personalidade
- Comunica√ß√£o clara e objetiva
- Foco em insights de neg√≥cio
- Sempre considera implica√ß√µes √©ticas
- Apresenta dados com storytelling eficaz

# Tarefa
Analise os dados de turnover fornecidos e identifique padr√µes, causas raiz e recomenda√ß√µes espec√≠ficas.

# Formato de Sa√≠da
- Resumo executivo (2-3 frases)
- Principais insights (bullet points)
- Recomenda√ß√µes acion√°veis (numeradas)
- Pr√≥ximos passos sugeridos

# Contexto Adicional
- Empresa de tecnologia com 500 funcion√°rios
- Foco em reten√ß√£o de talentos em tecnologia
- Budget limitado para initiatives de RH
```

## üéØ Zero-shot vs Few-shot Learning

### Zero-shot Learning

O modelo recebe apenas instru√ß√µes, sem exemplos espec√≠ficos:

```python
prompt = """
Classifique o sentimento do seguinte texto como Positivo, Negativo ou Neutro:

Texto: "O produto chegou mais r√°pido que o esperado e a qualidade √© excelente!"

Sentimento:
"""
```

### Few-shot Learning

O modelo recebe alguns exemplos para contextualizar o padr√£o:

```python
prompt = """
Classifique o sentimento dos textos como Positivo, Negativo ou Neutro:

Exemplo 1:
Texto: "Adorei o atendimento, muito profissional!"
Sentimento: Positivo

Exemplo 2:
Texto: "O produto chegou com defeito e o suporte n√£o ajudou."
Sentimento: Negativo

Exemplo 3:
Texto: "O produto √© ok, nada excepcional."
Sentimento: Neutro

Agora classifique:
Texto: "O produto chegou mais r√°pido que o esperado e a qualidade √© excelente!"
Sentimento:
"""
```

### Quando Usar Cada Abordagem

**Zero-shot:**
- Tarefas simples e diretas
- Quando voc√™ tem poucos exemplos
- Para explora√ß√£o inicial de capacidades

**Few-shot:**
- Tarefas complexas ou espec√≠ficas
- Quando voc√™ quer um formato espec√≠fico
- Para melhorar consist√™ncia de respostas

## üß† Chain-of-Thought (CoT) Prompting

O **Chain-of-Thought** encoraja o modelo a expor seu racioc√≠nio intermedi√°rio, melhorando respostas em tarefas complexas[^1].

### CoT B√°sico

```python
prompt = """
Preciso resolver este problema passo a passo:

Problema: Uma empresa tem 120 funcion√°rios. 30% trabalham remotamente, 
40% trabalham h√≠brido, e o resto trabalha presencial. Se 15 funcion√°rios 
remotos deixaram a empresa, qual √© a nova distribui√ß√£o?

Vamos pensar passo a passo:
"""
```

### CoT com Exemplos

```python
prompt = """
Resolva problemas matem√°ticos mostrando seu racioc√≠nio:

Exemplo:
Problema: Uma loja tinha 150 produtos. Vendeu 60 no primeiro dia e 40 no segundo. Quantos restaram?
Pensamento: 
1. Produtos iniciais: 150
2. Vendidos total: 60 + 40 = 100
3. Produtos restantes: 150 - 100 = 50
Resposta: 50 produtos

Agora resolva:
Problema: Uma empresa tem 120 funcion√°rios. 30% trabalham remotamente, 40% trabalham h√≠brido, e o resto trabalha presencial. Se 15 funcion√°rios remotos deixaram a empresa, qual √© a nova distribui√ß√£o?

Pensamento:
"""
```

### CoT para Agentes

```python
agent_prompt = """
Voc√™ √© um agente de an√°lise de dados. Para cada tarefa, siga este processo de racioc√≠nio:

1. **Compreens√£o**: O que est√° sendo pedido?
2. **Planejamento**: Quais passos preciso seguir?
3. **Execu√ß√£o**: Como vou realizar cada passo?
4. **Valida√ß√£o**: Os resultados fazem sentido?

Tarefa: {user_query}

Pensamento:
1. Compreens√£o:
"""
```

## üîÑ Meta-Prompting

**Meta-prompting** foca na estrutura abstrata da tarefa, usando instru√ß√µes ou modelos sint√°ticos que guiam o formato da resposta[^2].

### Template de Meta-Prompt

```python
meta_prompt_template = """
Voc√™ √© um sistema que segue padr√µes estruturados. Para qualquer tarefa, use este template:

## AN√ÅLISE
- **Objetivo**: [Defina claramente o objetivo]
- **Dados**: [Identifique os dados necess√°rios]
- **M√©todo**: [Escolha a abordagem]

## EXECU√á√ÉO
- **Passo 1**: [Primeira a√ß√£o]
- **Passo 2**: [Segunda a√ß√£o]
- **Passo N**: [A√ß√£o final]

## RESULTADO
- **Insights**: [Principais descobertas]
- **Recomenda√ß√µes**: [A√ß√µes sugeridas]
- **Confian√ßa**: [N√≠vel de confian√ßa 1-10]

Tarefa: {task_description}
"""
```

### Meta-Prompt para Diferentes Tipos de Tarefa

```python
def generate_meta_prompt(task_type: str) -> str:
    templates = {
        "analysis": """
        Use este padr√£o para an√°lises:
        1. CONTEXTO: Situa√ß√£o atual
        2. DADOS: Informa√ß√µes dispon√≠veis  
        3. AN√ÅLISE: Processamento dos dados
        4. INSIGHTS: Descobertas principais
        5. A√á√ïES: Pr√≥ximos passos
        """,
        
        "problem_solving": """
        Use este padr√£o para resolu√ß√£o de problemas:
        1. PROBLEMA: Defini√ß√£o clara
        2. CAUSAS: Poss√≠veis causas raiz
        3. SOLU√á√ïES: Alternativas dispon√≠veis
        4. AVALIA√á√ÉO: Pr√≥s e contras
        5. DECIS√ÉO: Recomenda√ß√£o final
        """,
        
        "creative": """
        Use este padr√£o para tarefas criativas:
        1. INSPIRA√á√ÉO: Fontes de ideias
        2. CONCEITO: Ideia central
        3. DESENVOLVIMENTO: Elabora√ß√£o
        4. REFINAMENTO: Melhorias
        5. APRESENTA√á√ÉO: Resultado final
        """
    }
    
    return templates.get(task_type, templates["analysis"])
```

## üîß T√©cnicas Avan√ßadas de Prompting

### 1. Self-Consistency

Execute o mesmo prompt m√∫ltiplas vezes e use vota√ß√£o majorit√°ria:

```python
def self_consistency_prompting(prompt: str, n_iterations: int = 5):
    responses = []
    
    for _ in range(n_iterations):
        response = llm.generate(prompt)
        responses.append(response)
    
    # Analisa consist√™ncia e retorna resposta mais comum
    return analyze_consistency(responses)
```

### 2. Tree of Thoughts

Explora m√∫ltiplos caminhos de racioc√≠nio:

```python
tree_prompt = """
Vamos explorar diferentes abordagens para este problema:

Problema: {problem}

Caminho 1: Abordagem Anal√≠tica
- Passo A1: [An√°lise quantitativa]
- Passo A2: [Modelagem estat√≠stica]

Caminho 2: Abordagem Qualitativa  
- Passo B1: [Pesquisa qualitativa]
- Passo B2: [An√°lise de padr√µes]

Caminho 3: Abordagem H√≠brida
- Passo C1: [Combina√ß√£o de m√©todos]
- Passo C2: [Valida√ß√£o cruzada]

Avalie cada caminho e escolha o melhor:
"""
```

### 3. Constitutional AI

Use princ√≠pios para orientar o comportamento:

```python
constitutional_prompt = """
Princ√≠pios que devem orientar suas respostas:
1. Precis√£o: Informa√ß√µes devem ser factualmente corretas
2. Transpar√™ncia: Indique quando h√° incerteza
3. √âtica: Considere implica√ß√µes √©ticas das recomenda√ß√µes
4. Praticidade: Foque em solu√ß√µes implement√°veis
5. Inclusividade: Considere impacto em todos os stakeholders

Tarefa: {task}

Siga os princ√≠pios acima para responder:
"""
```

## üé® Prompt Engineering para Agentes

### System Prompt para Agentes

```python
system_prompt = """
Voc√™ √© um agente de an√°lise de dados especializado em People Analytics.

IDENTIDADE:
- Nome: DataAgent
- Expertise: An√°lise de RH, estat√≠stica, visualiza√ß√£o
- Personalidade: Anal√≠tico, preciso, orientado a solu√ß√µes

CAPABILITIES:
- An√°lise explorat√≥ria de dados
- Visualiza√ß√µes e dashboards
- Modelagem preditiva
- Relat√≥rios executivos

TOOLS DISPON√çVEIS:
- query_database: Consulta bases de dados SQL
- create_visualization: Cria gr√°ficos e dashboards
- statistical_analysis: Executa an√°lises estat√≠sticas
- generate_report: Gera relat√≥rios formatados

PROCESSO DE TRABALHO:
1. Compreenda completamente a solicita√ß√£o
2. Identifique dados necess√°rios
3. Execute an√°lise apropriada
4. Crie visualiza√ß√µes relevantes
5. Forne√ßa insights acion√°veis

DIRETRIZES:
- Sempre valide qualidade dos dados
- Explique metodologia utilizada
- Considere limita√ß√µes e vieses
- Forne√ßa recomenda√ß√µes espec√≠ficas
"""
```

### Prompt Din√¢mico para Contexto

```python
def build_dynamic_prompt(user_query: str, context: dict) -> str:
    base_prompt = "Voc√™ √© um assistente de an√°lise de dados."
    
    # Adiciona contexto do usu√°rio
    if context.get("user_role"):
        base_prompt += f"\nUsu√°rio: {context['user_role']} com interesse em {context.get('focus_area', 'an√°lise geral')}."
    
    # Adiciona dados dispon√≠veis
    if context.get("available_data"):
        base_prompt += f"\nDados dispon√≠veis: {', '.join(context['available_data'])}"
    
    # Adiciona restri√ß√µes
    if context.get("constraints"):
        base_prompt += f"\nRestri√ß√µes: {context['constraints']}"
    
    # Adiciona query do usu√°rio
    base_prompt += f"\n\nSolicita√ß√£o: {user_query}"
    
    # Adiciona instru√ß√µes de formato
    base_prompt += "\n\nForne√ßa resposta estruturada com insights claros e recomenda√ß√µes acion√°veis."
    
    return base_prompt
```

## üìä Avalia√ß√£o de Prompts

### M√©tricas de Qualidade

```python
class PromptEvaluator:
    def __init__(self):
        self.metrics = [
            'relevance',
            'clarity', 
            'completeness',
            'actionability',
            'accuracy'
        ]
    
    def evaluate_prompt_response(self, prompt: str, response: str, expected_outcome: str = None) -> Dict[str, float]:
        scores = {}
        
        # Relev√¢ncia: Qu√£o relevante √© a resposta para o prompt
        scores['relevance'] = self._score_relevance(prompt, response)
        
        # Clareza: Qu√£o clara e compreens√≠vel √© a resposta
        scores['clarity'] = self._score_clarity(response)
        
        # Completude: Se a resposta aborda todos os aspectos solicitados
        scores['completeness'] = self._score_completeness(prompt, response)
        
        # Acionabilidade: Se a resposta cont√©m insights acion√°veis
        scores['actionability'] = self._score_actionability(response)
        
        # Precis√£o: Se dispon√≠vel, compara com resultado esperado
        if expected_outcome:
            scores['accuracy'] = self._score_accuracy(response, expected_outcome)
        
        scores['overall'] = sum(scores.values()) / len(scores)
        return scores
```

### A/B Testing de Prompts

```python
class PromptABTester:
    def __init__(self):
        self.experiments = {}
    
    def create_experiment(self, name: str, prompt_a: str, prompt_b: str):
        self.experiments[name] = {
            'prompt_a': prompt_a,
            'prompt_b': prompt_b,
            'results_a': [],
            'results_b': []
        }
    
    def run_test(self, experiment_name: str, test_queries: List[str], evaluator: PromptEvaluator):
        experiment = self.experiments[experiment_name]
        
        for query in test_queries:
            # Testa prompt A
            response_a = llm.generate(experiment['prompt_a'].format(query=query))
            score_a = evaluator.evaluate_prompt_response(experiment['prompt_a'], response_a)
            experiment['results_a'].append(score_a)
            
            # Testa prompt B  
            response_b = llm.generate(experiment['prompt_b'].format(query=query))
            score_b = evaluator.evaluate_prompt_response(experiment['prompt_b'], response_b)
            experiment['results_b'].append(score_b)
        
        return self._analyze_results(experiment_name)
```

## üöÄ Boas Pr√°ticas

### 1. Itera√ß√£o e Refinamento

```python
def iterative_prompt_development(initial_prompt: str, test_cases: List[dict], max_iterations: int = 5):
    current_prompt = initial_prompt
    
    for iteration in range(max_iterations):
        # Testa prompt atual
        results = test_prompt(current_prompt, test_cases)
        
        # Analisa falhas
        failures = [case for case in results if case['score'] < 0.7]
        
        if not failures:
            break  # Prompt est√° bom o suficiente
            
        # Refina prompt baseado em falhas
        current_prompt = refine_prompt_based_on_failures(current_prompt, failures)
    
    return current_prompt
```

### 2. Versionamento de Prompts

```python
class PromptVersionManager:
    def __init__(self):
        self.versions = {}
        self.current_versions = {}
    
    def save_prompt_version(self, prompt_id: str, prompt: str, metadata: dict = None):
        if prompt_id not in self.versions:
            self.versions[prompt_id] = []
        
        version = {
            'version': len(self.versions[prompt_id]) + 1,
            'prompt': prompt,
            'timestamp': datetime.now(),
            'metadata': metadata or {}
        }
        
        self.versions[prompt_id].append(version)
        self.current_versions[prompt_id] = version['version']
        
        return version['version']
    
    def get_prompt(self, prompt_id: str, version: int = None) -> str:
        if version is None:
            version = self.current_versions[prompt_id]
        
        return self.versions[prompt_id][version - 1]['prompt']
```

### 3. Prompt Libraries

```python
class PromptLibrary:
    def __init__(self):
        self.prompts = {
            'data_analysis': {
                'exploratory': "Realize uma an√°lise explorat√≥ria dos dados fornecidos...",
                'statistical': "Execute an√°lise estat√≠stica detalhada...",
                'predictive': "Desenvolva modelo preditivo para..."
            },
            'reporting': {
                'executive': "Crie relat√≥rio executivo resumindo...",
                'technical': "Prepare documenta√ß√£o t√©cnica detalhada...",
                'dashboard': "Gere especifica√ß√µes para dashboard..."
            },
            'problem_solving': {
                'root_cause': "Identifique as causas raiz do problema...",
                'solution_design': "Projete solu√ß√µes para o desafio...",
                'impact_analysis': "Analise o impacto das mudan√ßas propostas..."
            }
        }
    
    def get_prompt(self, category: str, type: str, **kwargs) -> str:
        template = self.prompts[category][type]
        return template.format(**kwargs)
```

---

[^1]: [Chain-of-Thought Prompting - Prompt Engineering Guide](https://www.promptingguide.ai/techniques/cot)
[^2]: [Meta Prompting - Prompt Engineering Guide](https://www.promptingguide.ai/techniques/meta-prompting)