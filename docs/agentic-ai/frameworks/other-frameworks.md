# üß© Outras Op√ß√µes de Frameworks

Al√©m dos frameworks principais, existem v√°rias outras op√ß√µes especializadas para diferentes casos de uso.

## Crew AI

Framework para coordenar m√∫ltiplos agentes especializados trabalhando em equipe.

```python
from crewai import Agent, Task, Crew

# Define agentes especializados
researcher = Agent(
    role='Pesquisador',
    goal='Coletar informa√ß√µes relevantes',
    backstory='Especialista em pesquisa...'
)

analyst = Agent(
    role='Analista',
    goal='Analisar dados coletados',
    backstory='Especialista em an√°lise...'
)

# Define tarefas
research_task = Task(
    description='Pesquisar sobre agentic AI',
    agent=researcher
)

analysis_task = Task(
    description='Analisar informa√ß√µes coletadas',
    agent=analyst
)

# Coordena trabalho em equipe
crew = Crew(
    agents=[researcher, analyst],
    tasks=[research_task, analysis_task]
)
```

### Quando usar Crew AI

- **Multi-agent workflows**: Quando voc√™ precisa de agentes especializados
- **Colabora√ß√£o**: Tarefas que se beneficiam de diferentes perspectivas
- **Role-playing**: Simula√ß√£o de equipes com pap√©is espec√≠ficos

## AutoGen (Microsoft)

Framework para conversas multi-agente com diferentes pap√©is.

```python
from autogen import AssistantAgent, UserProxyAgent

# Agente assistente
assistant = AssistantAgent(
    name="assistant",
    system_message="Voc√™ √© um assistente √∫til.",
    llm_config={"model": "gpt-4"}
)

# Agente proxy do usu√°rio
user_proxy = UserProxyAgent(
    name="user_proxy",
    human_input_mode="NEVER",
    code_execution_config={"work_dir": "coding"}
)

# Inicia conversa
user_proxy.initiate_chat(
    assistant,
    message="Analise dados de vendas e crie um relat√≥rio"
)
```

### Quando usar AutoGen

- **Conversas estruturadas**: Di√°logos entre agentes
- **Code execution**: Quando precisa executar c√≥digo gerado
- **Iterative refinement**: Melhorias iterativas atrav√©s de feedback

## Haystack

Plataforma para construir aplica√ß√µes de busca e QA com LLMs.

```python
from haystack import Pipeline
from haystack.components.retrievers import InMemoryBM25Retriever
from haystack.components.generators import OpenAIGenerator

# Pipeline de RAG
pipeline = Pipeline()
pipeline.add_component("retriever", InMemoryBM25Retriever(document_store))
pipeline.add_component("generator", OpenAIGenerator(model="gpt-4"))

pipeline.connect("retriever", "generator")

# Executa pipeline
result = pipeline.run({
    "retriever": {"query": "Como implementar RAG?"},
    "generator": {"prompt": "Responda baseado no contexto: {documents}"}
})
```

### Quando usar Haystack

- **Search applications**: Aplica√ß√µes focadas em busca
- **Document QA**: Sistemas de perguntas e respostas
- **Pipeline flexibility**: Necessidade de pipelines customiz√°veis

## Compara√ß√£o R√°pida

| Framework | Foco Principal | Complexidade | Ideal Para |
|-----------|----------------|--------------|------------|
| **Crew AI** | Multi-agent teams | M√©dia | Colabora√ß√£o entre agentes |
| **AutoGen** | Agent conversations | M√©dia | Di√°logos estruturados |
| **Haystack** | Search & QA | Alta | Aplica√ß√µes de busca |
